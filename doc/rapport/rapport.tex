\documentclass[10pt,a4paper]{article}
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{longtable}
\usepackage{minted}
\usepackage{caption}

\pagestyle{fancy}

% Entêtes et pieds de page
\lhead{TB: Platinum Parsing}
\chead{}
\rhead{HEIG-VD}
\lfoot{}
\cfoot{\thepage}
\rfoot{}

% Commands
\newcommand{\todo}[1]{\textcolor{red}{TODO\ifthenelse{\equal{#1}{}}{}{:} #1}}
\newcommand{\hs}[1]{\mintinline{haskell}{#1}}

% No subsubsection in tableofcontent
\setcounter{tocdepth}{2}

% source code listing
\definecolor{mintedbg}{rgb}{0.95,0.95,0.95}
\setminted{
	autogobble,
	linenos,
	%bgcolor=mintedbg,
	tabsize=2,
	breaklines,
	frame=single
}

\begin{document}
	
	% Page de titre
	\title{Platinum Parsing\\
		Travail de Bachelor}
	\author{Patrick Champion\\
		Prof. François Birling}
	\date{Printemps 2017\\
		HEIG-VD}
	\maketitle
	\vspace{6cm}
	\begin{figure}[H]
		\centering
		\todo{inclure logo ici}
	\end{figure}
	\thispagestyle{empty}
	\newpage
	
	% Page vide
	$ $ 
	\thispagestyle{empty}
	\newpage
	
	% Table des matières
	\tableofcontents
	\newpage
	
	\section*{Table des abréviations}
		Dans l'ordre alphabétique:\\
		\begin{itemize}
			\item \textbf{AST} \cite{ast} $\rightarrow$ Abstract Syntax Tree
			\item \textbf{BNF} \cite{bnf} $\rightarrow$ Backus-Naur Form
			\item \textbf{CLI} $\rightarrow$ Command Line Interface
			\item \textbf{EBNF} \cite{ebnf} $\rightarrow$ Extended Backus-Naur Form
			\item \textbf{GOLD} \cite{goldparser} $\rightarrow$ GOLD Parser System
			\item \textbf{LALR} \cite{lalr} $\rightarrow$ Look-Ahead LR parser
			\item \textbf{PP} $\rightarrow$ Platinum Parsing
			\item \textbf{TB} $\rightarrow$ Travail de Bachelor
		\end{itemize}
	\newpage
	
	\section{Introduction}
		\todo{à faire à la fin}
	
	\section{Études des cas d'utilisation}
	\label{sec:etudes-des-cas-d-utilisation}
	
		Afin d'analyser les fonctionnalités nécessaires de PP, nous allons utiliser une approche par cas d'utilisation. La première étape de cette analyse est de définir quels seront les acteurs qui auront besoin d'utiliser notre outil:
		\begin{itemize}
			\item le \textbf{concepteur} de langage veut pouvoir définir sa grammaire EBNF, ainsi que la vérifier (erreur de syntaxe, ambiguïté, etc.)
			\item le \textbf{développeur} de compilateur veut pouvoir se baser sur une grammaire EBNF pour construire facilement les règles de production. Il souhaite également avoir le contrôle sur la sortie produite, cela à l'aide d'un langage riche
			\item le \textbf{mainteneur} du compilateur veut pouvoir implémenter un parser en se basant sur des tables pré-générées, cela dans n'importe quel langage
			\item l'\textbf{utilisateur} du compilateur veut pouvoir l'utiliser simplement, celui-ci devrait aussi optionnellement fournir des options de compilation lui offrant un certain contrôle
		\end{itemize}
		
		À partir de ces acteurs, nous pouvons construire un diagramme des cas d'utilisation de PP:
		\begin{figure}[H]
			\centering
			\includegraphics[width=\textwidth]{../diagrams/use-case/use-case}
			\caption{Diagramme des cas d'utilisation}
		\end{figure}
		
		\subsection{Cahier des charges}
			Le diagramme ci-dessus nous offre un bon aperçu des fonctionnalités que nous devons implémenter. Nous allons cependant préciser par écrit celles-ci afin d'avoir un cahier des charges complet. Dans cette section les fonctionnalités utilisant \textit{doit} sont obligatoires, celles utilisant \textit{devrait} sont optionnelles:
			
			\begin{figure}[H]
				\centering
				\begin{longtable}{p{0.05\textwidth}p{0.8\textwidth}|p{0.05\textwidth}}
					\# & & Statut\\
					\hline\hline
					&&\\
					& Platinum Parsing: & \\
					10.10 & \textbf{doit} être un outil fournissant des fonctionnalités similaires à \textit{Gold Parsing System} & \\
					10.20 & \textbf{doit} être développé à l'aide de briques technologiques efficaces pour l'analyse de la BNF, la construction des tables LALR et la génération de code multilangage & \\
					10.30 & devrait être pensée pour avoir une approche générique du problème de la compilation & \\
					10.40 & devrait fournir une documentation complète de la solution & \\
					&&\\
					& Le module d'analyse de grammaire EBNF: & \\
					20.10 & \textbf{doit} lire et comprendre une grammaire selon la syntaxe EBNF & \\
					20.20 & \textbf{doit} analyser la validité d'une grammaire définie & \\
					20.30 & \textbf{doit} aider à la correction des erreurs de grammaire & \\
					20.40 & \textbf{doit} permettre de tester une grammaire pour la reconnaissance d'un texte en entrée & \\
					&&\\
					& Le module de génération de tables LALR: & \\
					30.10 & \textbf{doit} générer les tables selon une grammaire EBNF donnée & \\
					30.20 & \textbf{doit} être capable de traduire les tables selon un modèle fourni par l'utilisateur & \\
					30.30 & devrait fournir une documentation pour l'utilisation des tables générées & \\
					&&\\
					& L'arbre abstrait syntaxique: & \\
					40.10 & \textbf{doit} permettre d'attacher un \textit{callback} à ses noeuds & \\
					&&\\
					& L'environnement de développement: & \\
					50.10 & devrait soit être un IDE dédié ou un plugin pour un environnement existant & \\
					50.20 & devrait intégrer l'ensemble des fonctionnalités de Platinum Parsing pour en faciliter l'usage & \\
					&&\\
					& La solution finale: & \\
					60.10 & \textbf{doit} fournir une démonstration en développant un lexer et un parser en C\# pour le langage ISO CNC & \\
				\end{longtable}
			\end{figure}

	\section{Architecture du projet}
	\label{sec:architecture-du-projet}
		Dans cette section, nous allons poser l'architecture de PP. C'est-à-dire l'organisation générale des différentes fonctionnalités requises, ainsi que leur utilisation dans des cas réels.
	
		\subsection{GOLD Parser System \cite{goldparser}}
			Pour commencer, nous allons voir comment fonctionne GOLD Parser. le but de ce projet étant de remplacer GOLD, il s'agit d'un bon point de départ. En effet nous souhaitons proposer la même chose et, éventuellement, aller plus loin encore.\\
			
			Voici le schéma tel qu'expliqué sur le site de GOLD:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-gold-parser}
				\caption{Fonctionnement de GOLD Parser System}
			\end{figure}
			
			L'utilisation de GOLD se décompose en 2 étapes distinctes:
			\begin{enumerate}
				\item le développeur écrit la grammaire de son langage et utilise le \textit{Builder} pour générer une grammaire compilée (.cgt), constituée principalement des tables (LALR, ...) du langage en question. À partir de là, le \textit{Builder} n'est plus nécessaire
				\item le développeur implémente un \textit{Engine} (dans n'importe quel langage) qui s'occupe de charger la grammaire compilée et d'effectuer le \textit{parsing} des fichiers sources 
			\end{enumerate}
			
			Une des forces de GOLD est que de nombreuses personnes ont fournies une implémentation d'\textit{Engine} dans des langages de programmation différents. Ces \textit{Engine} étaient donc prêts a être utilisés, cela implique que le format du fichier .cgt doit être normalisé.\\
			
			Le désavantage de cette approche est qu'il n'est pas possible de réaliser toute la chaîne en une seule fois.
		
		\subsection{Décomposition en sous-projets}
			Avant de passer à la section suivante, qui explique comment PP sera organisé, nous allons rapidement définir à un niveau plus large quelles seront les différentes parties de PP:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth,trim={3cm 3cm 3cm 3cm},clip]{../diagrams/pipeline/pipeline-parts}
				\caption{Sous-projets de PP}
			\end{figure}
			
			Si nous partons du plus interne au plus externe, nous avons:
			\begin{itemize}
				\item le \textbf{framework}, qui n'est rien d'autre qu'un cadre de développement pour la création de compilateur. On peut le voir comme une collection de briques pré-créées extensible 
				\item le \textbf{CLI}, pour \textbf{C}ommand \textbf{L}ine \textbf{I}nterface, qui aide à l'utilisation du framework et qui propose d'autres outils spécifiques
				\item l'\textbf{IDE} (ou plugin pour un IDE existant), qui utilise principalement le CLI et qui connaît le framework pour offrir une meilleure expérience de développement\\
			\end{itemize}
			
			Ces explications sont encore assez abstraites et méritent d'être approfondies, cela sera fait dans les prochaines sections. Cependant nous préférons les introduire dès maintenant pour simplifier la lecture et la compréhension.
		
		\subsection{Organisation de Platinum Parsing}
			PP est un outil qui peut se décomposer en plusieurs étapes successives (un \textit{pipeline}), chacune prenant des données en entrée et fournissant d'autres données en sortie pour la prochaine étape du processus. Dans cette section nous allons expliciter quelles sont ces étapes ainsi que les données intermédiaires.\\
			
			Premièrement, définissons ce que nous avons besoin au niveau du framework. Nous voulons pouvoir transformer des fichiers sources en quelque chose d'autre:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-output} 
				\caption{Sorties possibles d'un exécutable créé avec PP}
			\end{figure}
			
			Nous voyons que ce \textit{quelque chose d'autre} peut prendre plusieurs formes: une interprétation directement, des fichiers transpilés, ou encore d'autres choses (ici en exemple des tables).\\
			
			Comment allons-nous créer cet exécutable? Ce prochain schéma va nous montrer cela, avec les acteurs des cas d'utilisation pour plus de clareté (voir \autoref{sec:etudes-des-cas-d-utilisation}):
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline} 
				\caption{Utilisation de PP pour créer un exécutable}
			\end{figure}
			
			On voit ici apparaître le framework ainsi que le CLI, comment cela fonctionne:
			\begin{enumerate}
				\item le concepteur crée sa grammaire EBNF
				\item le développeur utilise une fonctionnalité du CLI pour transformer la grammaire EBNF dans une grammaire compréhensible par le framework, les \textit{Rules}
				\item le développeur utilise les briques du framework et/ou crée ses propres briques
				\begin{itemize}
					\item c'est typiquement ici que la sortie sera décidée (interprétation, transpilation, etc.)
				\end{itemize}
				\item le développeur utilise le CLI pour créer l'exécutable final
				\item l'utilisateur utilise l'exécutable final\\
			\end{enumerate}
			
			Si l'on met les deux schémas précédents ensemble, nous obtenons:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-full} 
				\caption{Fonctionnement de PP}
			\end{figure}
			
			Ce schéma fait le parallèle entre GOLD et PP. Là où GOLD s'arrête à la transformation d'une grammaire en tables, PP est plus général et permet de transformer depuis n'importe quelle langage (définissable par les \textit{rules}) vers n'importe quelle sortie.\\
			
			Cependant les fonctionnalités de GOLD sont également intéressantes, et celles-ci peuvent être implémentées à l'aide de notre framework. Nous allons voir cela dans la section suivante.
			
		\subsection{Séparation des fonctionnalités framework/CLI}
			Pour séparer les fonctionnalités prévues entre le framework et le CLI, nous allons nous baser sur plusieurs exemples d'utilisation possible de PP. L'un de ces exemples suivra l'approche de GOLD, afin de prouver que PP est capable de faire la même chose si le développeur le souhaite.\\
			
			Nous avons déjà vu une séparation grâce aux précédents schémas, le reste est vu dans les cas ci-dessous:
			\begin{itemize}
				\item le \textbf{framework}:
				\begin{itemize}
					\item fourni un pipeline de développement pour tout le processus
					\item fourni un ou des \textit{builder}/\textit{engine} pré-définis
					\item fourni la gestion des options en ligne de commande
					\item est extensible pour permettre le changement de son comportement
				\end{itemize}
				\item le \textbf{CLI}:
				\begin{itemize}
					\item fourni des outils pour gérer les fichiers ainsi que l'arborescence dans un projet utilisant le framework
					\item exécute la chaîne de compilation complète du framework
					\item fourni des outils relatifs à l'élaboration d'une grammaire EBNF:
					\begin{itemize}
						\item transformation en \textit{Rules} compréhensibles par le framework
						\item vérification de la grammaire (cohérence, conflit, etc.)
						\item vérification de la grammaire en se basant sur des fichiers sources de ladite grammaire 
					\end{itemize}
					\item fourni un outil pour transformer une EBNF directement en tables (comme GOLD)
				\end{itemize}
			\end{itemize}
			
			\subsubsection{Cas 1: interprétation du langage Lua}
				Avant de commencer ce cas d'utilisation, expliquons rapidement le fonctionnement interne du framework:
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-framework} 
					\caption{Fonctionnement interne du framework (général)}
				\end{figure}
				
				On y retrouve les éléments des schémas précédents:
				\begin{enumerate}
					\item on définit notre grammaire, ce sont les \textit{Rules}
					\item le \textit{Builder}, à l'image de celui de GOLD, créer les tables (LALR, ...) en se basant sur les \textit{Rules}
					\item ces tables sont envoyés à l'\textit{Engine}, ainsi que les fichiers sources à traiter selon ces tables
					\item l'\textit{Engine} génère une sortie\\
				\end{enumerate}
				
				Le framework fourni un squelette pour que le développeur puisse faire ce qu'il veut dans l'\textit{Engine} sans avoir à se soucier de certain détails (le \textit{parser} typiquement).\\
				
				Si l'on revient sur notre cas:
				\begin{enumerate}
					\item on définit la grammaire Lua
					\item on implémente un \textit{Engine} pour interpréter Lua\\
				\end{enumerate}
				
				Et c'est tout! On compile et on peut utiliser notre exécutable.
			
			\subsubsection{Cas 2: transformation d'une grammaire EBNF en grammaire BNF}
				Ce cas ressemble beaucoup au cas précédent:
				\begin{enumerate}
					\item on définit la grammaire EBNF
					\item on implémente un \textit{Engine} pour transformer en BNF
				\end{enumerate}
			
			\subsubsection{Cas 3: transformation d'une grammaire EBNF en tables}
				Ce cas est plus intéressant, en effet il s'agit de la fonctionnalité principale de GOLD. Si nous reprenons le schéma précédent pour l'adapter à ce cas:
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-framework-gold} 
					\caption{Utilisation du framework pour recréer le \textit{Builder} de GOLD}
				\end{figure}
				
				\begin{enumerate}
					\item on définit la grammaire EBNF
					\item on implémente un \textit{Engine} qui sérialise les tables dans un fichier (.cgt pour faire la comparaison avec GOLD)\\
				\end{enumerate}
				
				Ce cas étant une fonctionnalité nécessaire au projet, nous pouvons l'inclure au CLI.
			
			\subsubsection{Cas 4: transformation d'une grammaire EBNF en tables, puis implémentation d'un \textit{engine} en Python}
				Ce cas est une utilisation typique de GOLD, voyons comment cela est fait avec PP:
				\begin{enumerate}
					\item on définit notre grammaire en EBNF
					\item on utilise le CLI pour créer les tables correspondantes (voir cas 3)
					\item on implémente un \textit{Engine} en Python qui utilise les tables\\
				\end{enumerate}
				
				On voit ici que le framework est très général, ainsi les fonctionnalités de GOLD plus spécifiques doivent être implémentées à part (à l'aide du framework) et être intégrées au CLI.

	\section{Technologies}
	
		\subsection{État de l'art}
			La génération de parser est un domaine qui possède déjà nombre d'outils. Le lien suivant propose une liste de ceux-ci avec leurs spécificités: \url{https://en.wikipedia.org/wiki/Comparison_of_parser_generators}\\
			
			Ces outils diffèrent notamment au niveau des points suivants:
			\begin{itemize}
				\item Algorithmes de \textit{parsing} utilisés
				\item Grammaires d'entrée acceptées
				\item Langages de sortie proposés
				\item Plateformes de développement possible
				\item Licence
			\end{itemize}
	
		\subsection{Choix du langage}
			Un choix crucial dans ce projet est le choix du langage de programmation que nous allons utiliser pour implémenter notre solution. Plusieurs langages ont été choisis en début de projet pour être comparés:
			\begin{itemize}
				\item C\# 
				\item F\#
				\item Haskell\\
			\end{itemize}
			
			Pour choisir entre ces différentes options, nous allons nous baser sur plusieurs critères pour lesquels chaque langage sera mis en compétition. Les critères fondamentaux sont éliminatifs, c'est-à-dire qu'un langage qui ne répondrait pas à l'un de ces critères est d'emblée supprimé: 
			\begin{figure}[H]
				\centering
				\begin{tabular}{|c|l|c|c|c|}
					\hline
					\textbf{No} & \textbf{Critère} & \textbf{C\#} & \textbf{F\#} & \textbf{Haskell}\\
					\hline
					\multicolumn{5}{|c|}{\textit{Critères fondamentaux}}\\
					\hline
					1 & Le langage a une communauté active et des ressources sur internet & Oui & Non & Oui\\
					2 & Le langage possède une ou des bibliothèques dans le domaine du \textit{parsing} & Oui & Oui & Oui\\
					3 & L'implémentation d'un parser de test simple est aisée & Oui & Oui & Oui\\
					\hline\hline
					\multicolumn{2}{|c|}{\textbf{Total}} & Oui & Non & Oui\\
					\hline
				\end{tabular}
				\caption{Critères pour le choix du langage et résultats}
			\end{figure}
			
			Les détails des critères testés se trouvent dans l'annexe \ref{subsec:criteres-testes-pour-le-choix-du-langage}.\\
			
			F\# se retrouve d'office éliminé pour cause d'une communauté trop peu active, ce qui n'est pas une bonne chose pour un projet. Cela nous laisse à choisir entre C\# et Haskell. Concernant les bibliothèques de \textit{parsing}, Irony pour C\# et Parsec pour Haskell, celles-ci offrent des possibilités similaires et sont simples à prendre en main, néanmoins Parsec possède des ressources (tutos, articles) plus complètes que Irony. À propos des paradigmes, multiple pour C\# et fonctionnel pur pour Haskell, ceux-ci apportent des approches différentes du problèmes. Cependant aucun est incapable de résoudre les problèmes liés à ce projet.\\
			
			Une différence entre l'implémentation du parser simplifié en C\# et en Haskell est la manipulation de l'AST. En effet en C\# les types des noeuds sont des \texttt{string}, le parcours est donc fait au \textit{runtime} à base de conditions \textit{if-else}. Haskell quant à lui permet de définir les types des noeuds de manière statique, ainsi le parcours de l'arbre se base sur du \textit{pattern matching}, ce qui amène à du code plus clair, plus court et plus sûr.\\
			
			Nous choisissons donc \textbf{Haskell} pour le développement de ce projet pour ses avantages suivants:
			\begin{itemize}
				\item Bonne communauté
				\item Beaucoup de ressources
				\item Bibliothèque Parsec efficace
				\item AST statique\\
			\end{itemize}
			
			Haskell possède également d'autres avantages et il est utilisé par de nombreuses entreprises pour certains projets, notamment il est populaire pour le \textit{lexing/parsing}. Voici quelques liens de départ pour en savoir plus:
			\begin{itemize}
				\item \url{https://wiki.haskell.org/Introduction}
				\item \url{https://wiki.haskell.org/Haskell_in_industry}\\
			\end{itemize}
			
			Cela sera également l'occasion de concevoir et développer un projet complet à l'aide d'un langage fonctionnel pur, chose que nous n'avons pas eu la possibilité de faire lors du cursus.
			
		\subsection{Cadre de développement}
			La gestion de ce projet utilise plusieurs outils pour sa réalisation, voici une liste pour référence:
			\begin{itemize}
				\item Git \cite{git} : Gestionnaire de version
				\subitem Github \cite{github} : Serveur Git (\url{https://github.com/chlablak/platinum-parsing})
				\item LaTeX \cite{latex} : Rédaction du rapport
				\item Haskell \cite{haskell} : Langage de développement
				\subitem Stack \cite{stack} : Gestionnaire de projet Haskell
				\subitem Cabal \cite{cabal} : Système de \textit{package} pour les projets Haskell
				\subitem Haddock \cite{haddock} : Générateur de documentation depuis les sources
				\item Atom \cite{atom} : Éditeur de texte\\
			\end{itemize}
			
			Le langage choisi étant Haskell, nous allons nous baser sur ces \textit{guidelines} pour le développement:\\ \url{https://wiki.haskell.org/Programming_guidelines}
		
	\section{Planification des tâches}
		Dans la \autoref{sec:architecture-du-projet} \textit{architecture du projet} nous avons poser la forme générale de Platinum Parsing, cependant cette approche reste très générale et nous devons à présent la réduire pour répondre efficacement aux objectifs principaux du projet. Cette section cherche à organiser le développement dans ce sens. Évidemment, une fois ces objectifs remplis, la suite logique est d'aller vers l'architecture générale.\\
		
		Rappelons donc les objectifs principaux:
		\begin{itemize}
			\item lire et comprendre une grammaire selon la syntaxe EBNF
			\item analyser la validité d'une grammaire définie
			\item aider à la correction des erreurs de grammaire
			\item permettre de tester la grammaire pour la reconnaissance d'un texte en entrée
			\item générer les tables selon une grammaire EBNF donnée
			\item être capable de traduire les tables selon un modèle fourni par l'utilisateur
			\item permettre d'attacher un \textit{callback} aux noeuds de l'AST
			\item fournir une démonstration en développant un lexer et un parser en C\# pour le langage ISO CNC\\
		\end{itemize}
		
		À partir de cette liste, nous pouvons organiser le développement en phases successives:
		\begin{enumerate}
			\item Choix et définition de la grammaire non-contextuelle $\rightarrow$ voir \autoref{sec:choix-et-definition-de-la-grammaire-non-contextuelle}
			\subitem + Définition de l'AST pour la grammaire choisie 
			\item Création d'un parser pour la grammaire $\rightarrow$ voir \autoref{sec:creation-d-un-parser-pour-la-grammaire}
			\subitem + Donnant en sortie l'AST correspondant
			\subitem + Test avec des grammaires
			\subitem + Intégration au CLI
			\item Génération de la table LALR à partir de l'AST
			\subitem + Test avec une grammaire simple
			\subitem + Intégration au CLI
			\item Définition de la grammaire du langage ISO CNC
			\subitem + Écriture d'un petit programme en ISO CNC
			\item Test d'une grammaire à partir d'un texte en entrée
			\subitem + Analyse de la validité de la grammaire
			\subitem + Aide à la correction des erreurs de grammaire 
			\subitem + Test avec des grammaires ambiguës simples
			\subitem + Intégration au CLI
			\item Génération des tables dans un langage cible selon un modèle
			\subitem + Intégration au CLI
			\item Utilisation des tables générées en C\#, en démonstration
			\subitem + Attache de \textit{callbacks} 
			\item \textit{Tests, améliorations, objectifs optionnels, etc.}\\
		\end{enumerate} 
		
		L'ordre est important car chaque étape dépend des précédentes. Les structures de données ainsi que les algorithmes seront choisis au fur et à mesure des recherches dans les phases. Il en va de même pour les schémas UML (classes, séquences, etc.), en effet le projet est assez conséquent et tout concevoir avant la réalisation n'est pas une bonne approche. De ce fait chaque étape est à voir comme un module à part entière, et chacun de ces modules aura sa conception propre. Puis, dès que l'on aura une vision plus précise du tout, on pourra expliquer plus facilement le fonctionnement générale de la solution.\\
		
		Cette façon de procéder a l'avantage d'être plus résistante aux changements que l'on pourrait vouloir faire. Un peu comme un développement agile par itérations. Bien évidemment, il ne faut pas perdre de vue le projet dans sa globalité lors de chaque étape.\\
		
		La tâche \textit{Intégration au CLI} se fait en parallèle des étapes. Toutes ces fonctionnalités allant dans le CLI pour être mise en commun, et fournir une interface utilisateur simple. Il paraît donc évident que le CLI doit être développé en même temps.
	
	\section{Choix et définition de la grammaire non-contextuelle}
	\label{sec:choix-et-definition-de-la-grammaire-non-contextuelle}
		Afin de créer le parser, l'utilisateur aura besoin de définir son langage à l'aide d'une grammaire. Le langage le plus connu pour cela est BNF, avec ces différentes variantes (qui elles-mêmes ont des variantes): EBNF et ABNF.\\
		
		Nous devons choisir quelle variante nous allons utiliser pour PP. ABNF est exclu car sa lisibilité n'est pas très bonne pour les humains, son utilisation est plutôt pour la définition de protocoles. Concernant BNF et EBNF, les deux offrent les mêmes possibilités mais EBNF est généralement plus lisible et agréable à utiliser. À cette adresse (\url{http://xahlee.info/parser/bnf_ebnf_abnf.html}) nous avons un bon résumé que je copie ici:
		\begin{quote}
			\textbf{Advantages over BNF}
			
			Any grammar defined in EBNF can also be represented in BNF though representations in the latter are generally lengthier. e.g., options and repetitions cannot be directly expressed in BNF and require the use of an intermediate rule or alternative production defined to be either nothing or the optional production for option, or either the repeated production of itself, recursively, for repetition. The same constructs can still be used in EBNF.\\
			
			The BNF uses the symbols ($<$, $>$, $|$, $::=$) for itself, but does not include quotes around terminal strings. This prevents these characters from being used in the languages, and requires a special symbol for the empty string. In EBNF, terminals are strictly enclosed within quotation marks ("..." or '...'). The angle brackets ("$<$...$>$") for nonterminals can be omitted.\\
			
			BNF syntax can only represent a rule in one line, whereas in EBNF a terminating character, the semicolon, marks the end of a rule.\\
			
			Furthermore, EBNF includes mechanisms for enhancements, defining the number of repetitions, excluding alternatives, comments, etc.\\
		\end{quote}
		
		Nous choisissons donc EBNF comme langage pour la grammaire d'entrée de PP. De plus il s'agit du seul des trois qui est défini par une norme officielle: ISO/IEC 14977:1996. Nous avons donc une base solide sur laquelle nous appuyer.
	
		\subsection{Définition de l'AST pour la grammaire choisie}
			À présent que le langage pour la grammaire a été choisi (EBNF), nous devons spécifier sa propre grammaire pour implémenter le parser. La norme ISO/IEC 14977:1996 nous donne cela, réécrit ci-après:
			
			\inputminted{ebnf}{../grammars/ebnf.ebnf}
			\captionof{listing}{EBNF utilisé pour se définir lui-même}
			
			\paragraph{}
			L'AST en Haskell de cette grammaire est faite à l'aide d'un type de donnée algébrique, qui traduit l'EBNF ci-dessus simplement et assez directement:
			
			\begin{minted}{haskell}
				newtype Syntax = Syntax [SyntaxRule]
				data SyntaxRule = SyntaxRule MetaIdentifier DefinitionsList
				newtype DefinitionsList = DefinitionsList [SingleDefinition]
				newtype SingleDefinition = SingleDefinition [Term]
				data Term = Term Factor (Maybe Exception)
				newtype Exception = Exception Factor
				data Factor = Factor (Maybe Integer) Primary
				data Primary
					= OptionalSequence DefinitionsList
					| RepeatedSequence DefinitionsList
					| GroupedSequence DefinitionsList
					| PrimaryMetaIdentifier MetaIdentifier
					| TerminalString String
					| Empty
				newtype MetaIdentifier = MetaIdentifier String
			\end{minted}
			\captionof{listing}{AST de l'EBNF en Haskell}
			
			\paragraph{}
			Notons que les commentaires ne sont pas représentés par l'AST, ni les \textit{special sequence} qui n'ont pas de signification utile.
			
	\section{Création d'un parser pour la grammaire}
	\label{sec:creation-d-un-parser-pour-la-grammaire}
		%+ Donnant en sortie l'AST correspondant
		Maintenant que nous avons notre grammaire ainsi que l'AST correspondant, nous pouvons implémenter un parser à l'aide de Parsec. Commençons par poser les premiers modules (fichiers Haskell) que nous allons utiliser: 
		\begin{figure}[H]
			\centering
			\begin{tabular}{ll}
				\hs{PP} & Import global des fonctionnalités de PP\\
				\hs{PP.Grammar} & Définition des fonctions communes aux différentes grammaires (classe de type)\\
				\hs{PP.Grammars.Ebnf} & Définition de la grammaire EBNF (AST, \textit{parsers}, instances)\\
			\end{tabular}
			\caption{Premiers modules de PP}
		\end{figure}
		
		Ces fichiers sont assez simples. Le gros du travail a été de créer les \textit{parsers} pour la grammaire EBNF, de la même manière que pour le \textit{parser} simple que nous avions fait lors du choix du langage. 
		
		\todo{expliquer \hs{PP.Grammar.InputGrammar}}
		
		Notons encore que les guillemets simples \texttt{'...'} pour les \textit{terminal string} ne sont pas supportés pour le moment, Parsec ne propose en effet pas de moyen rapide contrairement aux guillemets doubles qui sont eux très bien gérés. 
		
		\subsection{Test avec des grammaires}
			Afin de valider notre implémentation du \textit{parser} pour la grammaire EBNF, nous allons utiliser un framework de test d'Haskell: \texttt{Hspec} \cite{hspec}\\
			
			Cela nous permet d'automatiser les tests. Ainsi si nous devons modifier ultérieurement le \textit{parser}, nous pourrons relancer directement les tests.\\
			
			Nous allons utiliser des modules avec une hiérarchie proche de PP pour avoir un projet homogène:
			\begin{figure}[H]
				\centering
				\begin{tabular}{ll}
					\hs{Spec} & Regroupement des différents tests\\
					\hs{PPTest.Grammars.Ebnf} & Tests pour la grammaire EBNF\\
				\end{tabular}
				\caption{Premiers modules de test}
			\end{figure}  
			
			\todo{expliquer \texttt{Hspec}, utilité de \hs{stringify}}
			
			Ces tests nous ont révéler certains problèmes du \textit{parser}, cependant ceux-ci sont mineurs et nous allons donc simplement ouvrir des tickets pour les corriger plus tard:
			\begin{itemize}
				\item Le tiret étant admis dans les \textit{meta identifier}, la règle d'exception \mintinline{ebnf}{character - "'"} doit être écrite \mintinline{ebnf}{<character> - "'"} pour enlever l'ambigüité
				\item La règle \mintinline{ebnf}{a=<b>;} retourne une erreur sur le $<$ suivant le $=$, cela uniquement lorsque les deux sont collés 
			\end{itemize}
		
		\subsection{Intégration au CLI}
			Le CLI a trois tâches principales:
			\begin{enumerate}
				\item récupérer et comprendre les arguments passés au programme
				\item envoyer ces arguments à la bonne commande
				\item exécuter la commande correctement\\
			\end{enumerate}
			
			Pour parser les options de la ligne de commande, Haskell possède plusieurs bibliothèques pour nous simplifier la vie: \url{https://wiki.haskell.org/Command_line_option_parsers}. Parmi ces possibilités, nous allons choisir \texttt{optparse-applicative} \cite{optparse} car elle est moderne, populaire, et elle répond à nos besoins.\\
			
			L'organisation des modules du CLI se fait assez simplement à partir des tâches listées ci-dessus:
			\begin{figure}[H]
				\centering
				\begin{tabular}{ll}
					\hs{Main} & Traitement des arguments et délégation à la bonne commande\\
					\hs{Args} & Structure Haskell représentant les arguments possibles\\
					\hs{Cmd.Ebnf} & Implémentation des fonctionnalités de la commande \texttt{pp ebnf}\\
				\end{tabular}
				\caption{Premiers modules du CLI}
			\end{figure} 
			
			Actuellement la seule commande disponible donne le résultat suivant:
			\begin{minted}{console}
				prompt$ pp ebnf -f doc/grammars/ebnf.ebnf --minify
			\end{minted}
			\begin{minted}{console}
				<syntax>=<syntax rule>,{<syntax rule>};
				<syntax rule>=<meta identifier>,"=",<definitions list>,";";
				<definitions list>=<single definition>,{"|",<single definition>};
				...
			\end{minted}
			
			Ce qui correspond au \textit{parsing} du fichier \texttt{doc/grammars/ebnf.ebnf} en AST, puis on \hs{stringify} l'AST et on l'affiche.
			
	\section{Génération de la table LALR}		
		\todo{parler du dragon book, chapitre, ...\\}
		\todo{mettre des bouts de code\\}
	
		À présent que nous avons l'AST d'une grammaire, nous pouvons nous attaquer à la génération de la table LALR correspondante. Ce processus est assez complexe, nous allons donc d'abord séparer les différentes fonctions utiles et structures de données utilisées:
		\begin{enumerate}
			\item transformation des règles EBNF en règles canoniques
			\subitem soit une fonction \hs{rules :: InputGrammar ast => ast -> [Rule]} 
			\subitem avec \hs{data Rule = Rule String [Rule] | NonTerm String | Term Char | Empty} 
			
			\item augmenter la grammaire (\hs{[Rule]}) pour avoir la grammaire augmentée
			\subitem soit une fonction \hs{extend :: [Rule] -> Either String [Rule]}
			\subitem (on utilise le type \hs{Either} car la fonction peut échouer)
			
			\item générer les collections d'items LR(1) canonique pour la grammaire
			\subitem soit une fonction \hs{collection :: LrBuilder item => RuleSet -> LrCollection item}
			\subitem avec \hs{type LrCollection item = Vector (LrSet item)} 
			\subitem et \hs{type LrSet item = Set item}
			\subitem et \hs{data Lr1Item = Lr1Item Rule Int Rule}
			\subitem et qui aura besoin des fonctions suivantes: \hs{closure}, \hs{goto} et \hs{first}
			
			\item fusion de la collection LR(1) pour avoir une collection LALR(1) de plus petite taille
			\subitem soit une fonction \hs{fusion :: LrCollection Lr1Item -> LrCollection LalrItem}
			\subitem avec \hs{data LalrItem = LalrItem Rule Int Rule}
			
			\item génération de la table LALR proprement dite
			\subitem soit une fonction \hs{table :: LrBuilder item => LrCollection item -> LrTable}
			\subitem avec \hs{type LrTable = Map (Int, Rule) LrAction}
			\subitem et \hs{data LrAction = LrShift ... | LrReduce ... | ...}\\
		\end{enumerate}
		
		Si on prend en compte les dépendances entre les fonctions, nous obtenons l'ordre dans lequel nous devons implémenter chacune: \hs{rules}, \hs{extend}, \hs{first}, \hs{closure}, \hs{goto}, \hs{collection}, \hs{fusion} et pour finir \hs{table}.\\
		
		Voyons donc en premier la fonction \hs{rules}, qui transforme l'AST de EBNF en AST simplifié, tout en gardant le sens original des règles EBNF \cite{ebnftobnf}. Par exemple les règles \mintinline{ebnf}{a = [b]; b = "c" | "d";} seront transformées en \mintinline{ebnf}{a = b; a = ; b = 'c'; b = 'd';}. Pour cela nous définissons le type \hs{Rule} dans \hs{PP.Rule}, et nous ajoutons une fonction \hs{rules :: ast -> [Rule]} à la classe de type \hs{PP.Grammar.InputGrammar}. De ce fait nous devons implémenter cette fonction pour l'AST de l'EBNF, cela se fait dans \hs{PP.Grammars.Ebnf}. Les tests sont ajoutés au module \hs{PPTest.Grammars.Ebnf} naturellement.\\
		
		Passons à la fonction \hs{extend}. Celle-ci doit augmenter la grammaire, c'est-à-dire pour une grammaire \mintinline{ebnf}{a = b; b = 'c';} on aura: \mintinline{ebnf}{__start = a; a = b; b = 'c';}. Il est possible que la grammaire ne contienne aucune ou plusieurs règles de départ, cela doit être détecté évidemment. L'implémentation se trouve dans \hs{PP.Rule} et les tests dans \hs{PPTest.Rule}.\\
		
		La fonction suivante est \hs{first} qui doit construire l'ensemble PREMIER d'une règle. Pour optimiser cela, nous allons réunir tous ces ensembles dans une structure \hs{FirstSet}. De plus les calculs ne seront réalisés qu'une seule fois. Cela est également fait dans \hs{PP.Rule}.\\
		
		Faisons un résumé de ce que nous avons actuellement:
		\begin{minted}{haskell}
			let g = {- EBNF grammar -} :: String
			
			-- Construct EBNF AST
			let Right ast = parse g :: To Ebnf.Syntax
			
			-- Construct augmented grammar
			let Right g' = extend . rules $ ast 
			
			-- Construct RuleSet
			let rs = ruleSet g'
			
			-- Construct FirstSet
			let fs = firstSet rs
		\end{minted}
		\captionof{listing}{Passage d'une grammaire EBNF en \hs{RuleSet} et \hs{FirstSet}}
		
		\paragraph{}
		À présent nous pouvons attaquer la génération de la collection LR(1) canonique. Pour cela nous avons le module \hs{PP.Builder} qui contient la classe de type pour les différents \textit{builders} LR: \hs{LrBuilder}. Puis nous définissons un module \hs{PP.Builders.Lr1} qui contiendra l'instance de cette classe pour le type \hs{Lr1Item}. Les tests sont eux dans \hs{PPTest.Builders.Lr1}.\\
		
		La construction de la collection LALR peut être faîte à partir de la collection LR(1). Pour cela nous avons une fonction \hs{fusion} qui s'occupe de mettre ensemble les set d'items ayant le même coeur. L'implémentation se trouve dans \hs{PP.Builders.Lalr} et les tests dans \hs{PPTest.Builders.Lalr}.\\
		
		Pour finir, la construction de la table de \textit{parsing} LALR se trouve dans \hs{PP.Builders.Lalr}. Ce qui nous amène à l'API suivante (continuation du code ci-dessus):
		\begin{minted}{haskell}
			-- Construct the LALR items set collection
			let c = collection rs :: LrCollection LalrItem
			
			-- Construct the final LALR table
			let t = table c
			
			-- Get an action from the table (state 2, term 'c')
			action t 2 (Term 'c')
		\end{minted}
		\captionof{listing}{Passage du \hs{RuleSet} en \hs{LrTable}}
		
		\subsection{Test avec une grammaire simple}
			\todo{}
		
		\subsection{Intégration au CLI}
			\todo{}
			
	\section{TODO}
		\todo{organisation du dossier du projet\\}
		\todo{modules finaux de PP\\}

	\section{Conclusion}
		\todo{à faire à la fin}
	
	\section{Annexes}
	
		\subsection{Énoncé original}
			Pour faciliter l'écriture de compilateurs, ce travail de diplôme vise à réaliser un outil complet avec un environnement de développement intégré, permettant :
			\begin{itemize}
				\item d'éditer une grammaire selon une syntaxe de type BNF
				\item d'analyser automatiquement cette BNF, de détecter les erreurs de syntaxe, incohérences et conflits de règles.
				\item de générer dans n'importe quel langage de programmation cible, sur la base d'un template textuel fourni par l'utilisateur, les tables pour le lexer et le parser LALR.\\
			\end{itemize}
			
			Ce travail de diplôme vise à développer un outil capable de remplacer "Gold Parsing System", un outil libre intéressant, mais malheureusement fortement pénalisé par des bugs récurrents. L'IDE sera réalisé sous la forme d'un plugin du logiciel oStudio d'Objectis, avec les technologies très en vogue C\# et WPF. Le générateur de compilateurs sera mis en ligne sur Internet en libre accès, permettant à la communauté Internet de bénéficier gratuitement de cette technologie. 
			
		\subsection{Cahier des charges original}
			Les objectifs du travail sont :
			\begin{itemize}
				\item Analyser et formaliser la liste des fonctionnalités répondant aux besoins des différents types d'utilisateurs dans un cahier des charges fonctionnel.
				\item Concevoir l'architecture de la solution.
				\item Évaluer et sélectionner les briques technologiques à utiliser pour l'analyse de la BNF, la construction des tables LALR et la génération de code multilangage.
				\item Développer le module d'analyse BNF, capable de lire une grammaire selon la syntaxe EBNF, d'analyser la validité de la grammaire définie, d'aider la correction des erreurs et de tester la grammaire pour la reconnaissance d'un texte d'entrée.
				\item Développer un module de génération des tables LALR et capable de les traduire dans un code source selon des modèles fournis par l'utilisateur, ce qui permet de cibler différents langages.
				\item Intégrer l'ensemble dans un environnement de développement à sélectionner pour en faciliter l'usage.
				\item Réaliser une démonstration finale de la solution développée en développant un lexer et un parser pour langage ISO CNC en C\#.
				\item Fournir une documentation de conception et un rapport final du travail réalisé.
			\end{itemize}
			
		\subsection{Table des figures}
			\begingroup
				\renewcommand{\section}[2]{}
				\listoffigures
			\endgroup
			
		\subsection{Table des listings}
			\begingroup
				\renewcommand{\section}[2]{}
				\listoflistings
			\endgroup
			
		\subsection{Critères testés pour le choix du langage}
		\label{subsec:criteres-testes-pour-le-choix-du-langage}
			Cette section contient les détails des différents critères pour chaque langage testé. Pour rappel ces critères sont:
			\begin{enumerate}
				\item Le langage a une communauté active et des ressources sur internet
				\item Le langage possède une ou des bibliothèques dans le domaine du \textit{parsing}
				\item L'implémentation d'un parser de test simple est aisée\\
			\end{enumerate}
			
			Concernant le 3ème critère, comme nous devrons implémenter la grammaire EBNF dans le cadre de ce TB, nous allons créer pour ce test un parser pour une grammaire EBNF simplifiée. Puis nous allons tester ce parser sur le fichier suivant:
			\begin{verbatim}
				grammar=identifier;
				identifier=letter,<letter>,digit;
				letter='a'|'b'|'c';
				digit='1'|'2'|'3';
				<test>='un test',<test>;
				<a2>=<a>,<b>|<b>;
			\end{verbatim}
			
			Pour simplification, nous avons uniquement:
			\begin{itemize}
				\item la définition de règle avec \texttt{=} : \texttt{<rule>=<expr>;}
				\item la concaténation avec \texttt{,} : \texttt{<a>,<b>}
				\item le choix avec \texttt{|} : \texttt{<a>|<b>}
				\item les terminaux entourés par des guillemets simples: \texttt{'a'}
				\item les non-terminaux entourés par \texttt{<>} ou pas
				\item pas de gestion des espaces, tabulations, ...
				\item pas de gestion de la priorité des opérateurs, ni des parenthèses\\
			\end{itemize}
			
			Le parser doit pouvoir sortir l'AST correspondant.
					
			\subsubsection{Langage Haskell}
				Concernant Haskell, le lien suivant contient tous les pointeurs utiles en ressources: \url{https://www.haskell.org/documentation}. Pour ce qui est de la communauté, les questions et réponses sont quotidiennes sur \textit{stack overflow} ainsi que sur \textit{reddit}. Il y a également un wiki communautaire.\\
				
				Le lien suivant liste différentes bibliothèques présente pour ce langage: \url{https://wiki.haskell.org/Applications_and_libraries}. Plusieurs outils ou bibliothèques pour le parsing existent et sont listés ici: \url{https://wiki.haskell.org/Applications_and_libraries/Compiler_tools}. De plus ce langage est la base de plusieurs compilateurs, voir: \url{https://wiki.haskell.org/Applications_and_libraries/Compilers_and_interpreters}\\
				
				L'implémentation du parser simplifié se trouve dans le dossier \texttt{./trials/haskell-simple-ebnf/}. La taille du module EBNF fait moins de 50 lignes, comprenant l'AST ainsi que le parser. Nous avons utilisé la bibliothèque Parsec \cite{parsec} qui utilise une syntaxe très proche de l'EBNF, ce qui est très pratique. Pour 1 million d'itérations, le parsing prend environ 140ms. Notons qu'il y a de nombreuses ressources concernant Parsec.
				
				\inputminted{haskell}{../../trials/haskell-simple-ebnf/src/EBNF.hs}
				\captionof{listing}{Utilisation de Parsec avec Haskell}
		
			\subsubsection{Langage C\#}
				C\# est un langage développé par Microsoft avec la base de .NET derrière. Les ressources sur Internet ne manquent pas et la communauté est bonne.\\
				
				La bibliothèque Irony \cite{irony} permet de construire un parser très simplement. En effet Irony utilise la surcharge des opérateurs pour avoir une syntaxe proche de celle de l'EBNF, ce qui est très pratique.\\
				
				L'implémentation du parser simplifié se trouve dans le dossier \texttt{./trials/csharp-simple-ebnf}. La taille du module EBNF fait moins de 50 lignes, et est très simple à comprendre. Notons tout de même que Irony possède assez peu de ressources sur Internet.
				
				\inputminted{csharp}{../../trials/csharp-simple-ebnf/csharp-simple-ebnf/EBNF.cs}
				\captionof{listing}{Utilisation de Irony avec C\#}
			
			\subsubsection{Langage F\#}
				F\# possède plusieurs tutoriaux sur Internet et bénéficie de .NET derrière: \url{http://fsharp.org/learn.html}. Cependant les questions sur \textit{stack overflow} ne sont pas courante, et celles-ci ne reçoivent pas forcément des réponses. \\
				
				La bibliothèque FParsec \cite{fparsec} a une API équivalente à Parsec de Haskell. Il y a plusieurs tutoriaux et la documentation est claire.\\
				
				L'implémentation se trouve dans le dossier \texttt{./trials/fsharp-simple-ebnf}. Celle-ci est naturellement proche de celle en Haskell, cependant F\# oblige de définir une fonction avant qu'elle ne soit utilisée, et construire des règles récursives est plus compliqué. La taille du module EBNF fait également moins de 50 lignes.
				
				\inputminted{fsharp}{../../trials/fsharp-simple-ebnf/fsharp-simple-ebnf/EBNF.fs}
				\captionof{listing}{Utilisation de FParsec avec F\#}
	
		\subsection{Références}
			\begingroup
				\renewcommand{\section}[2]{}
				\begin{thebibliography}{9}
					
					\bibitem{bnf} BNF, Backus-Naur form,\\
						\url{https://en.wikipedia.org/wiki/Backus\%E2\%80\%93Naur_form}\\
						
					\bibitem{ebnf} EBNF, Extended Backus-Naur form, used to express a context-free grammar,\\ 
						\url{https://en.wikipedia.org/wiki/Extended\_Backus\%E2\%80\%93Naur_form},\\
						\url{https://www.iso.org/standard/26153.html},\\
						\url{http://standards.iso.org/ittf/PubliclyAvailableStandards/s026153_ISO_IEC_14977_1996(E).zip}\\
					
					\bibitem{goldparser} GOLD Parsing System, GOLD is a free parsing system that you can use to develop your own programming languages, scripting languages and interpreters,\\
						\url{http://www.goldparser.org/}\\
						
					\bibitem{lalr} LALR, Look-Ahead LR parser,\\
						\url{https://en.wikipedia.org/wiki/LALR_parser}\\
						
					\bibitem{irony} Irony, .NET Language Implementation Kit,\\
						\url{https://irony.codeplex.com/}\\
						
					\bibitem{ast} AST, Abstract Syntax Tree,\\
						\url{https://en.wikipedia.org/wiki/Abstract_syntax_tree}\\
						
					\bibitem{git} Git, free and open source distributed version control system,\\
						\url{https://git-scm.com/}\\
					
					\bibitem{github} Github, web-based Git or version control repository,\\
						\url{https://github.com/}\\
											
					\bibitem{latex} LaTeX, a document preparation system,\\
						\url{http://www.latex-project.org/}\\
					
					\bibitem{haskell} Haskell, a standardized, general-purpose purely functional programming language,\\
						\url{https://www.haskell.org/}\\
					
					\bibitem{stack} Stack, a cross-platform program for developing Haskell projects,\\
						\url{https://docs.haskellstack.org/en/stable/README/}\\
					
					\bibitem{cabal} Cabal, a system for building and packaging Haskell libraries and programs,\\
						\url{https://www.haskell.org/cabal/}\\	
					
					\bibitem{atom} Atom, a text editor that's modern, approachable, yet hackable to the core,\\
						\url{https://atom.io/}\\
					
					\bibitem{parsec} Parsec, an industrial-strength parser library for Haskell,\\
						\url{https://hackage.haskell.org/package/parsec}\\
						
					\bibitem{fparsec} FParsec, a parser combinator library for F\#,\\
						\url{http://www.quanttec.com/fparsec/}\\
						
					\bibitem{haddock} Haddock, A Haskell Documentation Tool,\\
						\url{https://www.haskell.org/haddock/}\\
						
					\bibitem{hspec} Hspec, A testing framework for Haskell,\\
						\url{http://hackage.haskell.org/package/hspec}\\
						
					\bibitem{optparse} optparse-applicative, parsing options on the command line,\\
						\url{https://hackage.haskell.org/package/optparse-applicative}\\
						
					\bibitem{ebnftobnf} EBNF to BNF,\\
						\url{http://lampwww.epfl.ch/teaching/archive/compilation-ssc/2000/part4/parsing/node3.html}\\
						
				\end{thebibliography}
			\endgroup
	
\end{document}\grid
