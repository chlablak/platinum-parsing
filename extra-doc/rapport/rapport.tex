\documentclass[10pt,a4paper]{article}
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=2.00cm, right=2.00cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{float}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{longtable}
\usepackage{minted}
\usepackage{caption}
\usepackage{dirtree}
\usepackage{tikz}
\usepackage{forest}

\usetikzlibrary{shapes,arrows,positioning,shadows,matrix,automata}
\pagestyle{fancy}

% Entêtes et pieds de page
\lhead{TB: Platinum Parsing}
\chead{}
\rhead{HEIG-VD}
\lfoot{}
\cfoot{\thepage}
\rfoot{}

% Commands
\newcommand{\todo}[1]{\textcolor{red}{TODO\ifthenelse{\equal{#1}{}}{}{:} #1}\\}
\newcommand{\hs}[1]{\mintinline{haskell}{#1}}

% No subsubsection in tableofcontent
\setcounter{tocdepth}{2}

% source code listing
\definecolor{mintedbg}{rgb}{0.95,0.95,0.95}
\setminted{
	autogobble,
	linenos,
	%bgcolor=mintedbg,
	tabsize=2,
	breaklines,
	frame=single
}

\begin{document}
	
	% Page de titre
	\title{Platinum Parsing\\
		Travail de Bachelor}
	\author{Patrick Champion\\
		Prof. François Birling}
	\date{Printemps 2017\\
		HEIG-VD}
	\maketitle
	\vspace{6cm}
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{../logo/logo.png}
	\end{figure}
	\thispagestyle{empty}
	\newpage
	
	% Page vide
	$ $ 
	\thispagestyle{empty}
	\newpage
	
	% Table des matières
	\tableofcontents
	\newpage
	
	\section*{Table des abréviations}
		Dans l'ordre alphabétique:\\
		\begin{itemize}
			\item \textbf{AST} \cite{ast} $\rightarrow$ \textit{Abstract Syntax Tree}
			\item \textbf{BNF} \cite{bnf} $\rightarrow$ \textit{Backus-Naur Form}
			\item \textbf{CLI} $\rightarrow$ \textit{Command Line Interface}
			\item \textbf{EBNF} \cite{ebnf} $\rightarrow$ \textit{Extended Backus-Naur Form}
			\item \textbf{GOLD} \cite{goldparser} $\rightarrow$ \textit{GOLD Parser System}
			\item \textbf{IDE} $\rightarrow$ \textit{Integrated development environment}
			\item \textbf{LALR} \cite{lalr} $\rightarrow$ \textit{Look-Ahead LR parser}
			\item \textbf{LR} \cite{lr} $\rightarrow$ \textit{LR parser}
			\item \textbf{PP} $\rightarrow$ \textit{Platinum Parsing}
			\item \textbf{TB} $\rightarrow$ Travail de Bachelor
		\end{itemize}
	\newpage
		
	\section{Définition du cadre du projet}
		Dans cette section, nous allons mettre les documents fournis au début du projet. Ainsi un lecteur pourra connaître les spécifications initiales.
		
		\subsection{Énoncé original}
			Pour faciliter l'écriture de compilateurs, ce travail de diplôme vise à réaliser un outil complet avec un environnement de développement intégré, permettant :
			\begin{itemize}
				\item D'éditer une grammaire selon une syntaxe de type BNF
				\item D'analyser automatiquement cette BNF, de détecter les erreurs de syntaxe, incohérences et conflits de règles.
				\item De générer dans n'importe quel langage de programmation cible, sur la base d'un template textuel fourni par l'utilisateur, les tables pour le lexer et le parser LALR.\\
			\end{itemize}
			
			Ce travail de diplôme vise à développer un outil capable de remplacer "Gold Parsing System", un outil libre intéressant, mais malheureusement fortement pénalisé par des bugs récurrents. L'IDE sera réalisé sous la forme d'un plugin du logiciel oStudio d'Objectis, avec les technologies très en vogue C\# et WPF. Le générateur de compilateurs sera mis en ligne sur Internet en libre accès, permettant à la communauté Internet de bénéficier gratuitement de cette technologie. 
			
		\subsection{Cahier des charges original}
			Les objectifs du travail sont :
			\begin{itemize}
				\item Analyser et formaliser la liste des fonctionnalités répondant aux besoins des différents types d'utilisateurs dans un cahier des charges fonctionnel.
				\item Concevoir l'architecture de la solution.
				\item Évaluer et sélectionner les briques technologiques à utiliser pour l'analyse de la BNF, la construction des tables LALR et la génération de code multilangage.
				\item Développer le module d'analyse BNF, capable de lire une grammaire selon la syntaxe EBNF, d'analyser la validité de la grammaire définie, d'aider la correction des erreurs et de tester la grammaire pour la reconnaissance d'un texte d'entrée.
				\item Développer un module de génération des tables LALR et capable de les traduire dans un code source selon des modèles fournis par l'utilisateur, ce qui permet de cibler différents langages.
				\item Intégrer l'ensemble dans un environnement de développement à sélectionner pour en faciliter l'usage.
				\item Réaliser une démonstration finale de la solution développée en développant un lexer et un parser pour langage ISO CNC en C\#.
				\item Fournir une documentation de conception et un rapport final du travail réalisé.
			\end{itemize}
	
	\section{Études des cas d'utilisation}
	\label{sec:etudes-des-cas-d-utilisation}
	
		Afin d'analyser les fonctionnalités nécessaires de PP, nous allons utiliser une approche par cas d'utilisation. La première étape de cette analyse est de définir quels seront les acteurs qui auront besoin d'utiliser notre outil:
		\begin{itemize}
			\item Le \textbf{concepteur} de langage veut pouvoir définir sa grammaire EBNF, ainsi que la vérifier (erreur de syntaxe, ambiguïté, etc.)
			\item Le \textbf{développeur} de compilateur veut pouvoir se baser sur une grammaire EBNF pour construire facilement les règles de production. Il souhaite également avoir le contrôle sur la sortie produite, cela à l'aide d'un langage riche
			\item Le \textbf{mainteneur} du compilateur veut pouvoir implémenter un parser en se basant sur des tables pré-générées, cela dans n'importe quel langage
			\item L'\textbf{utilisateur} du compilateur veut pouvoir l'utiliser simplement, celui-ci devrait aussi optionnellement fournir des options de compilation lui offrant un certain contrôle
		\end{itemize}
		
		À partir de ces acteurs, nous pouvons construire un diagramme des cas d'utilisation de PP:
		\begin{figure}[H]
			\centering
			\includegraphics[width=\textwidth]{../diagrams/use-case/use-case}
			\caption{Diagramme des cas d'utilisation}
		\end{figure}
		
		\subsection{Cahier des charges}
		\label{subsec:cahier-des-charges}
			Le diagramme ci-dessus nous offre un bon aperçu des fonctionnalités que nous devons implémenter. Nous allons cependant préciser par écrit celles-ci afin d'avoir un cahier des charges complet. Dans cette section les fonctionnalités utilisant \textit{doit} sont obligatoires, celles utilisant \textit{devrait} sont optionnelles:
			
			\begin{table}[H]
				\centering
				\begin{longtable}{p{0.05\textwidth}p{0.75\textwidth}|p{0.1\textwidth}}
					\# & & Statut\\
					\hline\hline
					&&\\
					& Platinum Parsing: & \\
					10.10 & \textbf{doit} être un outil fournissant des fonctionnalités similaires à \textit{Gold Parsing System} & \autoref{sec:architecture-du-projet} \\
					10.20 & \textbf{doit} être développé à l'aide de briques technologiques efficaces pour l'analyse de la BNF, la construction des tables LALR et la génération de code multilangage & \autoref{sec:choix-des-technologies}\\
					10.30 & devrait être pensée pour avoir une approche générique du problème de la compilation & \\
					10.40 & devrait fournir une documentation complète de la solution & \\
					&&\\
					& Le module d'analyse de grammaire EBNF: & \\
					20.10 & \textbf{doit} lire et comprendre une grammaire selon la syntaxe EBNF & \autoref{sec:creation-d-un-parser-pour-la-grammaire}\\
					20.20 & \textbf{doit} analyser la validité d'une grammaire définie & \autoref{sec:test-d-une-grammaire-a-partir-d-un-texte-en-entree}\\
					20.30 & \textbf{doit} aider à la correction des erreurs de grammaire & \autoref{sec:test-d-une-grammaire-a-partir-d-un-texte-en-entree}\\
					20.40 & \textbf{doit} permettre de tester une grammaire pour la reconnaissance d'un texte en entrée & \autoref{sec:test-d-une-grammaire-a-partir-d-un-texte-en-entree}\\
					&&\\
					& Le module de génération de tables LALR: & \\
					30.10 & \textbf{doit} générer les tables selon une grammaire EBNF donnée & \autoref{sec:generation-de-la-table-lalr}\\
					30.20 & \textbf{doit} être capable de traduire les tables selon un modèle fourni par l'utilisateur & \autoref{sec:generation-des-tables-dans-un-langage-cible}\\
					30.30 & devrait fournir une documentation pour l'utilisation des tables générées & \\
					&&\\
					& L'arbre abstrait syntaxique: & \\
					40.10 & \textbf{doit} permettre d'attacher un \textit{callback} à ses noeuds & \autoref{sec:demonstration-en-csharp}\\
					&&\\
					& L'environnement de développement: & \\
					50.10 & devrait soit être un IDE dédié ou un plugin pour un environnement existant & \\
					50.20 & devrait intégrer l'ensemble des fonctionnalités de Platinum Parsing pour en faciliter l'usage & \\
					&&\\
					& La solution finale: & \\
					60.10 & \textbf{doit} fournir une démonstration en développant un lexer et un parser en C\# pour le langage ISO CNC & \autoref{sec:demonstration-en-csharp}\\
				\end{longtable}
			\end{table}

	\section{Architecture du projet}
	\label{sec:architecture-du-projet}
		Dans cette section, nous allons poser l'architecture de PP. C'est-à-dire l'organisation générale des différentes fonctionnalités requises, ainsi que leur utilisation dans des cas réels.
	
		\subsection{GOLD Parser System \cite{goldparser}}
			Pour commencer, nous allons voir comment fonctionne GOLD Parser. le but de ce projet étant de remplacer GOLD, il s'agit d'un bon point de départ. En effet nous souhaitons proposer la même chose et, éventuellement, aller plus loin encore.\\
			
			Voici le schéma tel qu'expliqué sur le site de GOLD:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-gold-parser}
				\caption{Fonctionnement de GOLD Parser System}
			\end{figure}
			
			L'utilisation de GOLD se décompose en 2 étapes distinctes:
			\begin{enumerate}
				\item Le développeur écrit la grammaire de son langage et utilise le \textit{Builder} pour générer une grammaire compilée (.cgt), constituée principalement des tables (LALR, ...) du langage en question. À partir de là, le \textit{Builder} n'est plus nécessaire
				\item Le développeur implémente un \textit{Engine} (dans n'importe quel langage) qui s'occupe de charger la grammaire compilée et d'effectuer le \textit{parsing} des fichiers sources 
			\end{enumerate}
			
			Une des forces de GOLD est que de nombreuses personnes ont fournies une implémentation d'\textit{Engine} dans des langages de programmation différents. Ces \textit{Engine} étaient donc prêts a être utilisés, cela implique que le format du fichier .cgt doit être normalisé.\\
			
			Le désavantage de cette approche est qu'il n'est pas possible de réaliser toute la chaîne en une seule fois.
		
		\subsection{Décomposition en sous-projets}
			Avant de passer à la section suivante, qui explique comment PP sera organisé, nous allons rapidement définir à un niveau plus large quelles seront les différentes parties de PP:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\textwidth]{../diagrams/misc/architecture-pp}
				\caption{Sous-projets de PP}
			\end{figure}
			
			Si nous partons du plus interne au plus externe, nous avons:
			\begin{itemize}
				\item Le \textbf{framework}, qui n'est rien d'autre qu'un cadre de développement pour la création de compilateur. On peut le voir comme une collection de briques pré-créées extensible 
				\item Le \textbf{CLI}, pour \textbf{C}ommand \textbf{L}ine \textbf{I}nterface, qui aide à l'utilisation du framework et qui propose d'autres outils spécifiques
				\item L'\textbf{IDE} (ou plugin pour un IDE existant), qui utilise principalement le CLI et qui connaît le framework pour offrir une meilleure expérience de développement\\
			\end{itemize}
			
			Ces explications sont encore assez abstraites et méritent d'être approfondies, cela sera fait dans les prochaines sections. Cependant nous préférons les introduire dès maintenant pour simplifier la lecture et la compréhension.
		
		\subsection{Organisation de Platinum Parsing}
			PP est un outil qui peut se décomposer en plusieurs étapes successives (un \textit{pipeline}), chacune prenant des données en entrée et fournissant d'autres données en sortie pour la prochaine étape du processus. Dans cette section nous allons expliciter quelles sont ces étapes ainsi que les données intermédiaires.\\
			
			Premièrement, définissons ce que nous avons besoin au niveau du framework. Nous voulons pouvoir transformer des fichiers sources en quelque chose d'autre:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-output} 
				\caption{Sorties possibles d'un exécutable créé avec PP}
			\end{figure}
			
			Nous voyons que ce \textit{quelque chose d'autre} peut prendre plusieurs formes: une interprétation directement, des fichiers transpilés, ou encore d'autres choses (ici en exemple des tables).\\
			
			Comment allons-nous créer cet exécutable? Ce prochain schéma va nous montrer cela, avec les acteurs des cas d'utilisation pour plus de clareté (voir \autoref{sec:etudes-des-cas-d-utilisation}):
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline} 
				\caption{Utilisation de PP pour créer un exécutable}
			\end{figure}
			
			On voit ici apparaître le framework ainsi que le CLI, comment cela fonctionne:
			\begin{enumerate}
				\item Le concepteur crée sa grammaire EBNF
				\item Le développeur utilise une fonctionnalité du CLI pour transformer la grammaire EBNF dans une grammaire compréhensible par le framework, les \textit{Rules}
				\item Le développeur utilise les briques du framework et/ou crée ses propres briques
				\begin{itemize}
					\item C'est typiquement ici que la sortie sera décidée (interprétation, transpilation, etc.)
				\end{itemize}
				\item Le développeur utilise le CLI pour créer l'exécutable final
				\item L'utilisateur utilise l'exécutable final\\
			\end{enumerate}
			
			Si l'on met les deux schémas précédents ensemble, nous obtenons:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-full} 
				\caption{Fonctionnement de PP}
			\end{figure}
			
			Ce schéma fait le parallèle entre GOLD et PP. Là où GOLD s'arrête à la transformation d'une grammaire en tables, PP est plus général et permet de transformer depuis n'importe quelle langage (définissable par les \textit{rules}) vers n'importe quelle sortie.\\
			
			Cependant les fonctionnalités de GOLD sont également intéressantes, et celles-ci peuvent être implémentées à l'aide de notre framework. Nous allons voir cela dans la section suivante.
			
		\subsection{Séparation des fonctionnalités framework/CLI}
			Pour séparer les fonctionnalités prévues entre le framework et le CLI, nous allons nous baser sur plusieurs exemples d'utilisation possible de PP. L'un de ces exemples suivra l'approche de GOLD, afin de prouver que PP est capable de faire la même chose si le développeur le souhaite.\\
			
			Nous avons déjà vu une séparation grâce aux précédents schémas, le reste est vu dans les cas ci-dessous:
			\begin{itemize}
				\item Le \textbf{framework}:
				\begin{itemize}
					\item Fourni un pipeline de développement pour tout le processus
					\item Fourni un ou des \textit{builder}/\textit{engine} pré-définis
					\item Fourni la gestion des options en ligne de commande
					\item est extensible pour permettre le changement de son comportement
				\end{itemize}
				\item Le \textbf{CLI}:
				\begin{itemize}
					\item Fourni des outils pour gérer les fichiers ainsi que l'arborescence dans un projet utilisant le framework
					\item Exécute la chaîne de compilation complète du framework
					\item Fourni des outils relatifs à l'élaboration d'une grammaire EBNF:
					\begin{itemize}
						\item Transformation en \textit{Rules} compréhensibles par le framework
						\item Vérification de la grammaire (cohérence, conflit, etc.)
						\item Vérification de la grammaire en se basant sur des fichiers sources de ladite grammaire 
					\end{itemize}
					\item Fourni un outil pour transformer une EBNF directement en tables (comme GOLD)
				\end{itemize}
			\end{itemize}
			
			\subsubsection{Cas 1: interprétation du langage Lua}
				Avant de commencer ce cas d'utilisation, expliquons rapidement le fonctionnement interne du framework:
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-framework} 
					\caption{Fonctionnement interne du framework (général)}
				\end{figure}
				
				On y retrouve les éléments des schémas précédents:
				\begin{enumerate}
					\item On définit notre grammaire, ce sont les \textit{Rules}
					\item Le \textit{Builder}, à l'image de celui de GOLD, créer les tables (LALR, ...) en se basant sur les \textit{Rules}
					\item Ces tables sont envoyés à l'\textit{Engine}, ainsi que les fichiers sources à traiter selon ces tables
					\item L'\textit{Engine} génère une sortie\\
				\end{enumerate}
				
				Le framework fourni un squelette pour que le développeur puisse faire ce qu'il veut dans l'\textit{Engine} sans avoir à se soucier de certain détails (le \textit{parser} typiquement).\\
				
				Si l'on revient sur notre cas:
				\begin{enumerate}
					\item On définit la grammaire Lua
					\item On implémente un \textit{Engine} pour interpréter Lua\\
				\end{enumerate}
				
				Et c'est tout! On compile et on peut utiliser notre exécutable.
			
			\subsubsection{Cas 2: transformation d'une grammaire EBNF en grammaire BNF}
				Ce cas ressemble beaucoup au cas précédent:
				\begin{enumerate}
					\item On définit la grammaire EBNF
					\item On implémente un \textit{Engine} pour transformer en BNF
				\end{enumerate}
			
			\subsubsection{Cas 3: transformation d'une grammaire EBNF en tables}
				Ce cas est plus intéressant, en effet il s'agit de la fonctionnalité principale de GOLD. Si nous reprenons le schéma précédent pour l'adapter à ce cas:
				\begin{figure}[H]
					\centering
					\includegraphics[width=0.8\textwidth]{../diagrams/pipeline/pipeline-framework-gold} 
					\caption{Utilisation du framework pour recréer le \textit{Builder} de GOLD}
				\end{figure}
				
				\begin{enumerate}
					\item On définit la grammaire EBNF
					\item On implémente un \textit{Engine} qui sérialise les tables dans un fichier (.cgt pour faire la comparaison avec GOLD)\\
				\end{enumerate}
				
				Ce cas étant une fonctionnalité nécessaire au projet, nous pouvons l'inclure au CLI.
			
			\subsubsection{Cas 4: transformation d'une grammaire EBNF en tables, puis implémentation d'un \textit{engine} en Python}
				Ce cas est une utilisation typique de GOLD, voyons comment cela est fait avec PP:
				\begin{enumerate}
					\item On définit notre grammaire en EBNF
					\item On utilise le CLI pour créer les tables correspondantes (voir cas 3)
					\item On implémente un \textit{Engine} en Python qui utilise les tables\\
				\end{enumerate}
				
				On voit ici que le framework est très général, ainsi les fonctionnalités de GOLD plus spécifiques doivent être implémentées à part (à l'aide du framework) et être intégrées au CLI.

	\section{Choix des technologies}
	\label{sec:choix-des-technologies}
	
		\subsection{État de l'art}
			La génération de parser est un domaine qui possède déjà nombre d'outils. Le lien suivant propose une liste de ceux-ci avec leurs spécificités: \url{https://en.wikipedia.org/wiki/Comparison_of_parser_generators}\\
			
			Ces outils diffèrent notamment au niveau des points suivants:
			\begin{itemize}
				\item Algorithmes de \textit{parsing} utilisés
				\item Grammaires d'entrée acceptées
				\item Langages de sortie proposés
				\item Plateformes de développement possible
				\item Licence
			\end{itemize}
	
		\subsection{Choix du langage}
			Un choix crucial dans ce projet est le choix du langage de programmation que nous allons utiliser pour implémenter notre solution. Plusieurs langages ont été choisis en début de projet pour être comparés:
			\begin{itemize}
				\item C\# 
				\item F\#
				\item Haskell\\
			\end{itemize}
			
			Pour choisir entre ces différentes options, nous allons nous baser sur plusieurs critères pour lesquels chaque langage sera mis en compétition. Les critères fondamentaux sont éliminatifs, c'est-à-dire qu'un langage qui ne répondrait pas à l'un de ces critères est d'emblée supprimé: 
			\begin{table}[H]
				\centering
				\begin{tabular}{|c|l|c|c|c|}
					\hline
					\textbf{No} & \textbf{Critère} & \textbf{C\#} & \textbf{F\#} & \textbf{Haskell}\\
					\hline
					\multicolumn{5}{|c|}{\textit{Critères fondamentaux}}\\
					\hline
					1 & Le langage a une communauté active et des ressources sur internet & Oui & Non & Oui\\
					2 & Le langage possède une ou des bibliothèques dans le domaine du \textit{parsing} & Oui & Oui & Oui\\
					3 & L'implémentation d'un parser de test simple est aisée & Oui & Oui & Oui\\
					\hline\hline
					\multicolumn{2}{|c|}{\textbf{Total}} & Oui & Non & Oui\\
					\hline
				\end{tabular}
				\caption{Critères pour le choix du langage et résultats}
			\end{table}
			
			Les détails des critères testés se trouvent dans l'annexe \ref{subsec:criteres-testes-pour-le-choix-du-langage}.\\
			
			F\# se retrouve d'office éliminé pour cause d'une communauté trop peu active, ce qui n'est pas une bonne chose pour un projet. Cela nous laisse à choisir entre C\# et Haskell. Concernant les bibliothèques de \textit{parsing}, Irony pour C\# et Parsec pour Haskell, celles-ci offrent des possibilités similaires et sont simples à prendre en main, néanmoins Parsec possède des ressources (tutos, articles) plus complètes que Irony. À propos des paradigmes, multiple pour C\# et fonctionnel pur pour Haskell, ceux-ci apportent des approches différentes du problèmes. Cependant aucun est incapable de résoudre les problèmes liés à ce projet.\\
			
			Une différence entre l'implémentation du parser simplifié en C\# et en Haskell est la manipulation de l'AST. En effet en C\# les types des noeuds sont des \texttt{string}, le parcours est donc fait au \textit{runtime} à base de conditions \textit{if-else}. Haskell quant à lui permet de définir les types des noeuds de manière statique, ainsi le parcours de l'arbre se base sur du \textit{pattern matching}, ce qui amène à du code plus clair, plus court et plus sûr.\\
			
			Nous choisissons donc \textbf{Haskell} pour le développement de ce projet pour ses avantages suivants:
			\begin{itemize}
				\item Bonne communauté
				\item Beaucoup de ressources
				\item Bibliothèque Parsec efficace
				\item AST statique\\
			\end{itemize}
			
			Haskell possède également d'autres avantages et il est utilisé par de nombreuses entreprises pour certains projets, notamment il est populaire pour le \textit{lexing/parsing}. Voici quelques liens de départ pour en savoir plus:
			\begin{itemize}
				\item \url{https://wiki.haskell.org/Introduction}
				\item \url{https://wiki.haskell.org/Haskell_in_industry}\\
			\end{itemize}
			
			Cela sera également l'occasion de concevoir et développer un projet complet à l'aide d'un langage fonctionnel pur, chose que nous n'avons pas eu la possibilité de faire lors du cursus.
			
		\subsection{Cadre de développement}
			La gestion de ce projet utilise plusieurs outils pour sa réalisation, voici une liste pour référence:
			\begin{itemize}
				\item Git \cite{git} : Gestionnaire de version
				\subitem Github \cite{github} : Serveur Git (\url{https://github.com/chlablak/platinum-parsing})
				\item LaTeX \cite{latex} : Rédaction du rapport
				\item Haskell \cite{haskell} : Langage de développement
				\subitem Stack \cite{stack} : Gestionnaire de projet Haskell
				\subitem Cabal \cite{cabal} : Système de \textit{package} pour les projets Haskell
				\subitem Haddock \cite{haddock} : Générateur de documentation depuis les sources
				\item Atom \cite{atom} : Éditeur de texte\\
			\end{itemize}
			
			Le langage choisi étant Haskell, nous allons nous baser sur ces \textit{guidelines} pour le développement:\\ \url{https://wiki.haskell.org/Programming_guidelines}
		
	\section{Planification des tâches}
		Dans la \autoref{sec:architecture-du-projet} \textit{architecture du projet} nous avons poser la forme générale de Platinum Parsing, cependant cette approche reste très générale et nous devons à présent la réduire pour répondre efficacement aux objectifs principaux du projet. Cette section cherche à organiser le développement dans ce sens. Évidemment, une fois ces objectifs remplis, la suite logique est d'aller vers l'architecture générale.\\
		
		Rappelons donc les objectifs principaux:
		\begin{itemize}
			\item Lire et comprendre une grammaire selon la syntaxe EBNF
			\item Analyser la validité d'une grammaire définie
			\item Aider à la correction des erreurs de grammaire
			\item Permettre de tester la grammaire pour la reconnaissance d'un texte en entrée
			\item Générer les tables selon une grammaire EBNF donnée
			\item Être capable de traduire les tables selon un modèle fourni par l'utilisateur
			\item Permettre d'attacher un \textit{callback} aux noeuds de l'AST
			\item Fournir une démonstration en développant un lexer et un parser en C\# pour le langage ISO CNC\\
		\end{itemize}
		
		À partir de cette liste, nous pouvons organiser le développement en phases successives:
		\begin{enumerate}
			\item Choix et définition de la grammaire non-contextuelle $\rightarrow$ voir \autoref{sec:choix-et-definition-de-la-grammaire-non-contextuelle}
			\subitem + Définition de l'AST pour la grammaire choisie 
			\item Création d'un parser pour la grammaire $\rightarrow$ voir \autoref{sec:creation-d-un-parser-pour-la-grammaire}
			\subitem + Donnant en sortie l'AST correspondant
			\subitem + Test avec des grammaires
			\subitem + Intégration au CLI
			\item Génération de la table LALR à partir de l'AST
			\subitem + Test avec une grammaire simple
			\subitem + Intégration au CLI
			\item Définition de la grammaire du langage ISO CNC
			\subitem + Écriture d'un petit programme en ISO CNC
			\item Test d'une grammaire à partir d'un texte en entrée
			\subitem + Analyse de la validité de la grammaire
			\subitem + Aide à la correction des erreurs de grammaire 
			\subitem + Test avec des grammaires ambiguës simples
			\subitem + Intégration au CLI
			\item Génération des tables dans un langage cible selon un modèle
			\subitem + Intégration au CLI
			\item Utilisation des tables générées en C\#, en démonstration
			\subitem + Attache de \textit{callbacks} 
			\item \textit{Tests, améliorations, objectifs optionnels, etc.}\\
		\end{enumerate} 
		
		L'ordre est important car chaque étape dépend des précédentes. Les structures de données ainsi que les algorithmes seront choisis au fur et à mesure des recherches dans les phases. Il en va de même pour les schémas UML (classes, séquences, etc.), en effet le projet est assez conséquent et tout concevoir avant la réalisation n'est pas une bonne approche. De ce fait chaque étape est à voir comme un module à part entière, et chacun de ces modules aura sa conception propre. Puis, dès que l'on aura une vision plus précise du tout, on pourra expliquer plus facilement le fonctionnement générale de la solution.\\
		
		Cette façon de procéder a l'avantage d'être plus résistante aux changements que l'on pourrait vouloir faire. Un peu comme un développement agile par itérations. Bien évidemment, il ne faut pas perdre de vue le projet dans sa globalité lors de chaque étape.\\
		
		La tâche \textit{Intégration au CLI} se fait en parallèle des étapes. Toutes ces fonctionnalités allant dans le CLI pour être mise en commun, et fournir une interface utilisateur simple. Il paraît donc évident que le CLI doit être développé en même temps.
	
	\section{Choix et définition de la grammaire non-contextuelle}
	\label{sec:choix-et-definition-de-la-grammaire-non-contextuelle}
		Afin de créer le parser, l'utilisateur aura besoin de définir son langage à l'aide d'une grammaire. Le langage le plus connu pour cela est BNF, avec ces différentes variantes (qui elles-mêmes ont des variantes): EBNF et ABNF.\\
		
		Nous devons choisir quelle variante nous allons utiliser pour PP. ABNF est exclu car sa lisibilité n'est pas très bonne pour les humains, son utilisation est plutôt pour la définition de protocoles. Concernant BNF et EBNF, les deux offrent les mêmes possibilités mais EBNF est généralement plus lisible et agréable à utiliser. À cette adresse (\url{http://xahlee.info/parser/bnf_ebnf_abnf.html}) nous avons un bon résumé que je copie ici:
		\begin{quote}
			\textbf{Advantages over BNF}
			
			Any grammar defined in EBNF can also be represented in BNF though representations in the latter are generally lengthier. e.g., options and repetitions cannot be directly expressed in BNF and require the use of an intermediate rule or alternative production defined to be either nothing or the optional production for option, or either the repeated production of itself, recursively, for repetition. The same constructs can still be used in EBNF.\\
			
			The BNF uses the symbols ($<$, $>$, $|$, $::=$) for itself, but does not include quotes around terminal strings. This prevents these characters from being used in the languages, and requires a special symbol for the empty string. In EBNF, terminals are strictly enclosed within quotation marks ("..." or '...'). The angle brackets ("$<$...$>$") for nonterminals can be omitted.\\
			
			BNF syntax can only represent a rule in one line, whereas in EBNF a terminating character, the semicolon, marks the end of a rule.\\
			
			Furthermore, EBNF includes mechanisms for enhancements, defining the number of repetitions, excluding alternatives, comments, etc.\\
		\end{quote}
		
		Nous choisissons donc EBNF comme langage pour la grammaire d'entrée de PP. De plus il s'agit du seul des trois qui est défini par une norme officielle: ISO/IEC 14977:1996. Nous avons donc une base solide sur laquelle nous appuyer.
	
		\subsection{Définition de l'AST pour la grammaire choisie}
			À présent que le langage pour la grammaire a été choisi (EBNF), nous devons spécifier sa propre grammaire pour implémenter le parser. La norme ISO/IEC 14977:1996 nous donne cela, réécrit ci-après:
			
			\inputminted{ebnf}{../../doc/grammars/ebnf.ebnf}
			\captionof{listing}{EBNF utilisé pour se définir lui-même}
			
			\paragraph{}
			L'AST en Haskell de cette grammaire est faite à l'aide d'un type de donnée algébrique, qui traduit l'EBNF ci-dessus simplement et assez directement:
			
			\begin{minted}{haskell}
				newtype Syntax = Syntax [SyntaxRule]
				data SyntaxRule = SyntaxRule MetaIdentifier DefinitionsList
				newtype DefinitionsList = DefinitionsList [SingleDefinition]
				newtype SingleDefinition = SingleDefinition [Term]
				data Term = Term Factor (Maybe Exception)
				newtype Exception = Exception Factor
				data Factor = Factor (Maybe Integer) Primary
				data Primary
					= OptionalSequence DefinitionsList
					| RepeatedSequence DefinitionsList
					| GroupedSequence DefinitionsList
					| PrimaryMetaIdentifier MetaIdentifier
					| TerminalString String
					| Empty
				newtype MetaIdentifier = MetaIdentifier String
			\end{minted}
			\captionof{listing}{AST de l'EBNF en Haskell}
			
			\paragraph{}
			Notons que les commentaires ne sont pas représentés par l'AST, ni les \textit{special sequence} qui n'ont pas de signification utile.
			
	\section{Création d'un parser pour la grammaire}
	\label{sec:creation-d-un-parser-pour-la-grammaire}
		%+ Donnant en sortie l'AST correspondant
		Maintenant que nous avons notre grammaire ainsi que l'AST correspondant, nous pouvons implémenter un parser à l'aide de Parsec. Commençons par poser les premiers modules (fichiers Haskell) que nous allons utiliser: 
		\begin{table}[H]
			\centering
			\begin{tabular}{ll}
				\hs{PP} & Import global des fonctionnalités de PP\\
				\hs{PP.Grammar} & Définition des fonctions communes aux différentes grammaires (classe de type)\\
				\hs{PP.Grammars.Ebnf} & Définition de la grammaire EBNF (AST, \textit{parsers}, instances)\\
			\end{tabular}
			\caption{Premiers modules de PP}
		\end{table}
		
		Ces fichiers sont assez simples. Le gros du travail a été de créer les \textit{parsers} pour la grammaire EBNF, de la même manière que pour le \textit{parser} simple que nous avions fait lors du choix du langage.\\
		
		La classe de type \hs{PP.Grammar.InputGrammar} définit les fonctions communes à tous les AST, on peut voir cela comme une interface en Java.\\
		
		Notons encore que les guillemets simples \texttt{'...'} pour les \textit{terminal string} ne sont pas supportés pour le moment, Parsec ne propose en effet pas de moyen rapide contrairement aux guillemets doubles qui sont eux très bien gérés. 
		
		\subsection{Test avec des grammaires}
			Afin de valider notre implémentation du \textit{parser} pour la grammaire EBNF, nous allons utiliser un framework de test d'Haskell: \texttt{Hspec} \cite{hspec}\\
			
			Cela nous permet d'automatiser les tests. Ainsi si nous devons modifier ultérieurement le \textit{parser}, nous pourrons relancer directement les tests.\\
			
			Nous allons utiliser des modules avec une hiérarchie proche de PP pour avoir un projet homogène:
			\begin{table}[H]
				\centering
				\begin{tabular}{ll}
					\hs{Spec} & Regroupement des différents tests\\
					\hs{PPTest.Grammars.Ebnf} & Tests pour la grammaire EBNF\\
				\end{tabular}
				\caption{Premiers modules de test}
			\end{table}  
			
			Ces tests nous ont révéler certains problèmes du \textit{parser}, cependant ceux-ci sont mineurs et nous allons donc simplement ouvrir des tickets pour les corriger plus tard:
			\begin{itemize}
				\item Le tiret étant admis dans les \textit{meta identifier}, la règle d'exception \mintinline{ebnf}{character - "'"} doit être écrite \mintinline{ebnf}{<character> - "'"} pour enlever l'ambigüité
				\item La règle \mintinline{ebnf}{a=<b>;} retourne une erreur sur le $<$ suivant le $=$, cela uniquement lorsque les deux sont collés 
			\end{itemize}
		
		\subsection{Intégration au CLI}
			Le CLI a trois tâches principales:
			\begin{enumerate}
				\item Récupérer et comprendre les arguments passés au programme
				\item Envoyer ces arguments à la bonne commande
				\item Exécuter la commande correctement\\
			\end{enumerate}
			
			Pour parser les options de la ligne de commande, Haskell possède plusieurs bibliothèques pour nous simplifier la vie: \url{https://wiki.haskell.org/Command_line_option_parsers}. Parmi ces possibilités, nous allons choisir \texttt{optparse-applicative} \cite{optparse} car elle est moderne, populaire, et elle répond à nos besoins.\\
			
			L'organisation des modules du CLI se fait assez simplement à partir des tâches listées ci-dessus:
			\begin{table}[H]
				\centering
				\begin{tabular}{ll}
					\hs{Main} & Traitement des arguments et délégation à la bonne commande\\
					\hs{Args} & Structure Haskell représentant les arguments possibles\\
					\hs{Cmd.Ebnf} & Implémentation des fonctionnalités de la commande \texttt{pp ebnf}\\
				\end{tabular}
				\caption{Premiers modules du CLI}
			\end{table} 
			
			Actuellement la seule commande disponible donne le résultat suivant:
			\begin{minted}{console}
				$ pp ebnf -f doc/grammars/ebnf.ebnf --minify
				<syntax>=<syntax rule>,{<syntax rule>};
				<syntax rule>=<meta identifier>,"=",<definitions list>,";";
				<definitions list>=<single definition>,{"|",<single definition>};
				...
			\end{minted}
			\captionof{listing}{Première commande du CLI}
			
			\paragraph{}
			Ce qui correspond au \textit{parsing} du fichier \texttt{doc/grammars/ebnf.ebnf} en AST, puis on \hs{stringify} l'AST et on l'affiche.
			
	\section{Génération de la table LALR}
	\label{sec:generation-de-la-table-lalr}	
		À présent que nous avons l'AST d'une grammaire, nous pouvons nous attaquer à la génération de la table LALR correspondante. Ce processus est assez complexe, nous allons donc d'abord séparer les différentes fonctions utiles et structures de données utilisées:
		\begin{enumerate}
			\item Transformation des règles EBNF en règles canoniques
			\subitem Soit une fonction \hs{rules :: InputGrammar ast => ast -> [Rule]} 
			\subitem Avec \hs{data Rule = Rule String [Rule] | NonTerm String | Term Char | Empty} 
			
			\item Augmenter la grammaire (\hs{[Rule]}) pour avoir la grammaire augmentée
			\subitem Soit une fonction \hs{extend :: [Rule] -> Either String [Rule]}
			\subitem (on utilise le type \hs{Either} car la fonction peut échouer)
			
			\item Générer les collections d'items LR(1) canonique pour la grammaire
			\subitem Soit une fonction \hs{collection :: LrBuilder item => RuleSet -> FirstSet -> LrCollection item}
			\subitem Avec \hs{type LrCollection item = Vector (LrSet item)} 
			\subitem Et \hs{type LrSet item = Set item}
			\subitem Et \hs{data Lr1Item = Lr1Item Rule Int Rule}
			\subitem Et qui aura besoin des fonctions suivantes: \hs{closure}, \hs{goto} et \hs{first}
			
			\item Fusion de la collection LR(1) pour avoir une collection LALR(1) de plus petite taille
			\subitem Soit une fonction \hs{fusion :: LrCollection Lr1Item -> LrCollection LalrItem}
			\subitem Avec \hs{data LalrItem = LalrItem Rule Int Rule}
			
			\item Génération de la table LALR proprement dite
			\subitem Soit une fonction \hs{table :: LrBuilder item => LrCollection item -> LrTable}
			\subitem Avec \hs{type LrTable = Map (Int, Rule) LrAction}
			\subitem Et \hs{data LrAction = LrShift ... | LrReduce ... | ...}\\
		\end{enumerate}
		
		Si on prend en compte les dépendances entre les fonctions, nous obtenons l'ordre dans lequel nous devons implémenter chacune: \hs{rules}, \hs{extend}, \hs{first}, \hs{closure}, \hs{goto}, \hs{collection}, \hs{fusion} et pour finir \hs{table}.\\
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.6\textwidth]{../diagrams/misc/generation-process}
			\caption{Processus de génération de la table LALR}
		\end{figure}
		
		Voyons donc en premier la fonction \hs{rules}, qui transforme l'AST de EBNF en AST simplifié, tout en gardant le sens original des règles EBNF \cite{ebnftobnf}. Par exemple les règles \mintinline{ebnf}{a = [b]; b = "c" | "d";} seront transformées en \mintinline{ebnf}{a = b; a = ; b = 'c'; b = 'd';}. Pour cela nous définissons le type \hs{Rule} dans \hs{PP.Rule}, et nous ajoutons une fonction \hs{rules :: ast -> [Rule]} à la classe de type \hs{PP.Grammar.InputGrammar}. De ce fait nous devons implémenter cette fonction pour l'AST de l'EBNF, cela se fait dans \hs{PP.Grammars.Ebnf}. Les tests sont ajoutés au module \hs{PPTest.Grammars.Ebnf} naturellement.\\
		
		Passons à la fonction \hs{extend}. Celle-ci doit augmenter la grammaire, c'est-à-dire pour une grammaire \mintinline{ebnf}{a = b; b = 'c';} on aura: \mintinline{ebnf}{__start = a; a = b; b = 'c';}. Il est possible que la grammaire ne contienne aucune ou plusieurs règles de départ, cela doit être détecté évidemment. L'implémentation se trouve dans \hs{PP.Rule} et les tests dans \hs{PPTest.Rule}.\\
		
		La fonction suivante est \hs{first} qui doit construire l'ensemble PREMIER d'une règle. Pour optimiser cela, nous allons réunir tous ces ensembles dans une structure \hs{FirstSet}. De plus les calculs ne seront réalisés qu'une seule fois. Cela est également fait dans \hs{PP.Rule}.\\
		
		Faisons un résumé de ce que nous avons actuellement:
		\begin{minted}{haskell}
			let g = {- EBNF grammar -} :: String
			
			-- Construct EBNF AST
			let Right ast = parse g :: To Ebnf.Syntax
			
			-- Construct augmented grammar
			let Right g' = extend . rules $ ast 
			
			-- Construct RuleSet
			let rs = ruleSet g'
			
			-- Construct FirstSet
			let fs = firstSet rs
		\end{minted}
		\captionof{listing}{Passage d'une grammaire EBNF en \hs{RuleSet} et \hs{FirstSet}}
		
		\paragraph{}
		À présent nous pouvons attaquer la génération de la collection LR(1) canonique. Pour cela nous avons le module \hs{PP.Builder} qui contient la classe de type pour les différents \textit{builders} LR: \hs{LrBuilder}. Puis nous définissons un module \hs{PP.Builders.Lr1} qui contiendra l'instance de cette classe pour le type \hs{Lr1Item}. Les tests sont eux dans \hs{PPTest.Builders.Lr1}.\\
		
		La construction de la collection LALR peut être faîte à partir de la collection LR(1). Pour cela nous avons une fonction \hs{fusion} qui s'occupe de mettre ensemble les set d'items ayant le même coeur. L'implémentation se trouve dans \hs{PP.Builders.Lalr} et les tests dans \hs{PPTest.Builders.Lalr}.\\
		
		Pour finir, la construction de la table de \textit{parsing} LALR se trouve dans \hs{PP.Builders.Lalr}. Ce qui nous amène à l'API suivante (continuation du code ci-dessus):
		\begin{minted}{haskell}
			-- Construct the LALR items set collection
			let c = collection rs fs :: LrCollection LalrItem
			
			-- Construct the final LALR table
			let t = table c
			
			-- Get an action from the table (state 2, term 'c')
			action t 2 (Term 'c')
		\end{minted}
		\captionof{listing}{Passage du \hs{RuleSet} en \hs{LrTable}}
		
		\paragraph{}
		L'implémentation ci-dessus se base sur le Dragon Book \cite{dragonbook}, chapitres 4.7 à 4.7.4. Les chapitres suivants proposent une construction plus efficace (en terme de mémoire notamment) de la table LALR, cela pourrait faire l'objet d'une amélioration pour plus tard.\\
		
		Notons que la table n'est pas stockée comme un tableau à deux dimensions. En effet, une bonne partie de la table est positionnée à \hs{LrError}, il ne sert à rien de stocker cela. Nous utilisons donc une \hs{Data.Map.Strict} à la place: \url{http://hackage.haskell.org/package/containers-0.5.10.2/docs/Data-Map-Strict.html}.
		
		\subsection{Test avec une grammaire simple}
			Les tests ont utilisés la grammaire suivantes:
			\begin{minted}{ebnf}
				S = C, C;
				C = "c", C | "d";
			\end{minted}
			Tirée du Dragon Book \cite{dragonbook}, afin d'avoir une référence fiable sur les bons résultats à obtenir.
		
		\subsection{Intégration au CLI}
			L'intégration au CLI se fait dans le module \hs{Cmd.Lalr}, les différentes options sont:
			\begin{minted}{console}
				$ pp lalr --help
				Usage: pp lalr (-g|--grammar FILENAME) [--collection] [--set I] [--table]
					Generate LALR parsing table
				
				Available options:
					-g,--grammar FILENAME    Input grammar (EBNF)
					--collection             Print the items sets collection
					--set I                  Print a specific items set
					--table                  Print the LALR parsing table
					-h,--help                Show this help text
			\end{minted}
			\captionof{listing}{Aide de la commande LALR du CLI}
			
			\paragraph{}
			L'affichage de la table LALR (flag \texttt{--table}) s'affiche encore comme la \hs{Map} qui contient la table, cela fera l'objet d'une amélioration future.
			
	\section{Définition de la grammaire du langage ISO CNC}
		À présent que nous avons un générateur de table LALR, et avant d'implémenter le \textit{parser} LALR même, nous allons définir la grammaire EBNF du langage ISO CNC \cite{gcode}. Cela nous permettra d'avoir une base pour les tests à venir.\\
		
		Pour écrire cette grammaire, celle-ci n'étant pas trouvable sur Internet, nous partons d'un programme écrit en ISO CNC et on en extrait des règles de production. Nous pouvons procéder ainsi car nous avons seulement besoin d'une grammaire pour les tests, pas une grammaire exacte du langage ISO CNC.\\
		
		Le programme se trouve dans le dossier \texttt{trials/iso-cnc-prog/}, la grammaire quant à elle dans le fichier \texttt{doc/grammars/iso-cnc.ebnf}. Pour le moment cela n'est qu'un premier jet, nous avons besoin d'implémenter la partie suivante (test des grammaires) pour la vérifier et éventuellement la corriger. Nous reviendrons donc dessus à la fin de la prochaine section.
		
	\section{Test d'une grammaire à partir d'un texte en entrée}
	\label{sec:test-d-une-grammaire-a-partir-d-un-texte-en-entree}
		Dans cette section nous nous intéressons aux tests possibles sur une grammaire, afin de la valider. Commençons par isoler les différentes erreurs possibles dans notre cas:
		\begin{enumerate}
			\item Syntaxe de la grammaire fausse
			\item Transformation en règles canoniques impossible
			\item Impossible d'augmenter la grammaire
			\item Non-terminal manquant
			\item Récursion à gauche (directe et indirecte)
			\item Grammaire non-LALR
			\item Grammaire invalide pour le langage voulu\\
		\end{enumerate} 
		
		Les points 1 à 3 sont actuellement déjà géré par PP. Nous allons donc commencer par les points 4 et 5, qui peuvent être détectés directement au niveau des règles canoniques. Nous ajoutons donc une fonction dans \hs{PP.Rule}:
		\begin{minted}{haskell}
			check :: RuleSet -> ([String], [String])
		\end{minted}
		\captionof{listing}{Signature de la fonction \hs{PP.Rule.check}}
		
		\paragraph{}
		Celle-ci prend un ensemble de règles canoniques, et retourne une paire \hs{(errors, warnings)} avec \hs{errors} une liste de non-terminaux manquants et/ou ayant une récursion à gauche (uniquement directe pour le moment), et \hs{warnings} une liste des non-terminaux inutilisés. Cette approche nous permet d'ajouter d'autres types d'erreurs et/ou \textit{warnings} sans avoir à toucher une autre partie du code.\\
		
		Passons maintenant au point 6, une grammaire est non-LALR si, lors de la génération de la table, des conflits \textit{shift/reduce} et/ou \textit{reduce/reduce} apparaissent. Ces conflits sont ignorés par la fonction de génération actuelle, cependant ajouter leur détection est très simple:
		\begin{minted}{haskell}
			-- Ancienne version 
			table :: LrCollection item -> LrTable
			
			-- Nouvelle version avec détection des conflits
			table :: LrCollection item -> Either [String] LrTable
		\end{minted}
		\captionof{listing}{Modification de \hs{PP.Builder.table} pour détecter les conflits}
		
		\paragraph{}
		Pour finir penchons-nous sur le point 7. Pour celui-ci nous avons une table LALR générée correctement, et on souhaite valider si cette table \textit{parse} effectivement le langage défini par la grammaire. Cela nécessite l'implémentation d'un \textit{parser} LR:
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\draw (3,4) rectangle (5,5) node[pos=.5] {Input};
				\draw (0,2) rectangle (2,3) node[pos=.5] {State stack};
				\draw (3,2) rectangle (5,3) node[pos=.5] {Parser LR};
				\draw (6,2) rectangle (8,3) node[pos=.5] {Output};
				\draw (3,0) rectangle (5,1) node[pos=.5] {LALR table};
				
				\draw[->] (3,2.5) -- (2,2.5);
				\draw[->] (5,2.5) -- (6,2.5);
				\draw[->] (4,3) -- (4,4);
				\draw[->] (4,2) -- (4,1);
			\end{tikzpicture}
			\caption{Schéma d'un analyseur syntaxique (\textit{parser})}
		\end{figure}
		
		Que nous allons mettre dans les modules suivants:
		\begin{table}[H]
			\centering
			\begin{tabular}{ll}
				\hs{PP.Parser} & Classe de type pour les \textit{parsers}\\
				\hs{PP.Parsers.Lr} & Implémentation du \textit{parser} LR\\
			\end{tabular}
		\end{table}
		
		L'implémentation minimale d'un \textit{parser} LR se trouve dans la classe de type:
		\begin{minted}{haskell}
			class LrParser config where
				config :: LrTable -> String -> config
				next :: LrTable -> config -> config
				hasNext :: LrTable -> config -> Bool
		\end{minted}
		\captionof{listing}{Classe de type (minimale) \hs{PP.Parser.LrParser}}
		
		\paragraph{}
		\hs{config} prend la chaîne en entrée et la place dans une configuration de départ. \hs{next} effectue une itération du \textit{parser} et \hs{hasNext} vérifie si il reste une itération à effectuer, ce qui n'est plus le cas lorsque une erreur est rencontrée, ou lorsque l'entrée a été acceptée. La classe de type est complétée par une fonction \hs{parse :: LrTable -> config -> config} qui effectue le \textit{parsing} complet. Notons qu'il y a aussi une fonction \hs{parse' :: LrTable -> config -> [config]} qui fait la même chose que \hs{parse}, mais en gardant toutes les configurations intermédiaires.\\
		
		La configuration pour notre \textit{parser} LR est la suivante:
		\begin{minted}{haskell}
			-- |Configuration for LR parser
			data LrConfig = LrConfig
				{ lrCount  :: Int        -- ^Counter
				, lrStack  :: [Int]      -- ^State stack
				, lrAction :: LrAction   -- ^Action to do
				, lrInput  :: String     -- ^Input
				} deriving (Eq, Show)
		\end{minted}
		\captionof{listing}{Configuration d'un \textit{parser} LR}
		
		\paragraph{}
		Grâce à cette fonction \hs{parse'} nous pouvons, au niveau du CLI,  afficher toutes les configurations de l'analyse syntaxique ayant pu amener à une erreur. L'objectif du point 7 est donc rempli. \\
		
		Les tests ont été ajoutés aux modules suivants:
		\begin{table}[H]
			\centering
			\begin{tabular}{ll}
				\hs{PPTest.Rule} & \textit{should check a rules set for missing non-terminals}\\
				& \textit{should check a rules set for unused non-terminals}\\
				& \textit{should check a rules set for direct left recursion}\\
				\hs{PPTest.Builders.Lalr} & \textit{should detect conflicts during the table generation}\\
				\hs{PPTest.Parsers.Lr} & \textit{should build the first configuration}\\
				& \textit{should parse a simple grammar correctly}\\
				& \textit{should detect an error in input}\\
			\end{tabular}
		\end{table}
		
		\subsection{Intégration au CLI}
		\label{subsec:test-grammaire-integration-au-cli}
			L'intégration au CLI est très simple et vient en l'ajout de deux nouveaux arguments: \texttt{--check} et \texttt{--test-with}. Afin de mettre en évidence leur utilisation et la détection correcte des erreurs (en plus des tests unitaires), nous avons mis dans le dossier \texttt{doc/grammars/wrong} des grammaires fausses mettant en évidence les différents problèmes possibles.\\
			
			Comme exemples:
			\begin{minted}{console}
				$ pp ebnf -f doc/grammars/wrong/03-direct-left-recursion.ebnf --check
				[PP][INFO] starting...
				[PP][INFO] verbosity: 30
				[PP][EBNF][CHECK][INFO] errors:
				[PP][EBNF][CHECK][INFO] direct left-recusion: A
				[PP][EBNF][CHECK][INFO] warnings:
				
				$ pp lalr -f doc/grammars/test.ebnf --test-with ignored/test.txt 
				[PP][INFO] starting...
				[PP][INFO] verbosity: 30
				[PP][LALR][TASK][START] compute collection and table
				[PP][LALR][TASK][END] in 5ms, compute collection and table
				[PP][LALR][INFO] after 32 iterations: 
				[PP][LALR][INFO] input accepted
				
				$ pp lalr -f doc/grammars/test.ebnf --test-with ignored/test.txt 
				[PP][INFO] starting...
				[PP][INFO] verbosity: 30
				[PP][LALR][TASK][START] compute collection and table
				[PP][LALR][TASK][END] in 2ms, compute collection and table
				[PP][LALR][INFO] after 44 iterations: 
				[PP][LALR][ERROR] error at ")+x)\n"
			\end{minted}
			\captionof{listing}{Exemples de tests avec le CLI}
			
			\subsubsection{\textit{Refactoring} du CLI}
				Si l'intégration au CLI était simple, cela a mis en évidence un problème d'organisation du CLI. En effet le \hs{Main} redirigeait les arguments à la bonne commande, et celle-ci utilisait ceux-ci directement:
				\begin{minted}{haskell}
					-- |Dispatch arguments to commands (Main)
					dispatch :: Args -> IO ()
					dispatch a@(Args _ (EbnfCmd _)) = Cmd.Ebnf.dispatch a
					dispatch a@(Args _ (LalrCmd _)) = Cmd.Lalr.dispatch a
					
					-- |Command dispatch (Cmd.Lalr)
					dispatch :: Args -> IO ()
					dispatch (Args (CommonArgs verbose) (LalrCmd (LalrArgs {- ... -}))) = do
						-- ... 
						when verbose $ -- ...
						-- ...
						
					-- |Command dispatch (Cmd.Ebnf)
					dispatch :: Args -> IO ()
					dispatch (Args (CommonArgs verbose) (EbnfCmd (EbnfArgs {- ... -}))) = do
						-- ... 
						when verbose $ -- ...
						-- ...
				\end{minted} 
				\captionof{listing}{Première version de l'organisation du CLI}
				
				\paragraph{}
				Le principal problème, entre autre, de cette approche, est que la gestion de la \textit{verbosity level} était propre à chaque commande, amenant à du code difficile à maintenir. Nous avons donc ajouter un module \hs{Log} qui s'occupera de tout ce qui est IO, ainsi les fonctions seront plus claires et l'affichage sera uniforme pour toutes les commandes.\\
				
				Le \hs{Main} devient donc un peu plus compliqué, cependant cette approche sépare mieux les responsabilités entre les modules et la maintenance devient plus aisée:
				\begin{minted}{haskell}
					-- |Dispatch arguments to commands (Main)
					dispatch :: Args -> Log.Logger
					dispatch args@(Args (CommonArgs l) _) = do
						Log.start l "pp"
						Log.autoFlush True
						Log.info "starting..."
						Log.info $ "verbosity: " ++ show l
						dispatch' args
							where
								dispatch' :: Args -> Log.Logger
								dispatch' a@(Args _ (EbnfCmd _)) = Cmd.Ebnf.dispatch a
								dispatch' a@(Args _ (LalrCmd _)) = Cmd.Lalr.dispatch a
								
					-- |Command dispatch (Ebnf)
					dispatch :: Args -> Log.Logger
					dispatch (Args _ (EbnfCmd args)) = do
						Log.pushTag "ebnf"
						-- tout est gere par `Log` 
				\end{minted}
				\captionof{listing}{Nouvelle version de l'organisation du CLI}
				
				\paragraph{}
				Un exemple de la nouvelle sortie (avec les tags) peut être vu dans les exemples de la \autoref{subsec:test-grammaire-integration-au-cli}.
			
		\subsection{Validation de la grammaire ISO CNC}
			\todo{reporté car finalement pas urgent}
			
		\subsection{Test sur une grammaire C modifiée}
			\todo{reporté pour des tests en phase III}
			
	\section{Génération des tables dans un langage cible}
	\label{sec:generation-des-tables-dans-un-langage-cible}
		Maintenant que les tests ont été réalisés, nous pouvons nous pencher sur la génération de la table LALR dans un langage autre que Haskell. Pour cela nous avons besoin de deux choses: un modèle (\textit{template}) sur lequel se baser, et donc un moteur de \textit{template}.\\
		
		Il existe plusieurs bibliothèques pour cela (\url{https://stackoverflow.com/questions/5770168/templating-packages-for-haskell}), nos choix sont \texttt{heterocephalus} \cite{heterocephalus} qui propose une syntaxe simple avec l'interpolation de variables, ainsi que des structures de contrôles (\texttt{if}, \texttt{forall}, ...) qui seront nécessaires dans notre cas, et \texttt{HStringTemplate} \cite{hstringtemplate} qui propose à peu près la même chose.\\
		
		Pour le choix final entre ces deux moteurs, nous allons mettre en évidence certaines de leurs caractéristiques par rapport à nos besoins:
		\begin{table}[H]
			\centering
			\begin{tabular}{l|cc}
				\textbf{Caractéristique} & \textbf{\texttt{heterocephalus}} & \textbf{\texttt{HStringTemplate}}\\
				\hline
				Modèle pré-compilé & Oui & \textbf{Non}\\
				Interpolation typé & \textbf{Oui} & Non\\
				Interpolation de variable & \textbf{Oui} & \textbf{Oui}\\
				Structure conditionnelle & \textbf{Oui} & \textbf{Oui}\\
				Structure de boucle & \textbf{Oui} & \textbf{Oui}\\
				Langage extensible & \textbf{Oui} & Non\\
			\end{tabular}
			\caption{Choix du \textit{template engine}}
		\end{table}
		
		Cette table montre que \texttt{heterocephalus} est plus riche que \texttt{HStringTemplate}, cela est principalement du au fait que le \textit{template} de l'utilisateur est compilé à la compilation et pas à l'exécution. Cependant cette méthode oblige à recompiler le CLI à chaque fois qu'on créer un nouveau \textit{template}, ce qui n'est pas notre objectif. Nous allons donc utiliser \texttt{HStringTemplate}, ses faiblesses au niveau du langage devront cependant être compensées par plus de variables \textit{interpolables}.\\
		
		Une autre option serait de créer notre propre moteur qui répondrait parfaitement à nos besoins. Néanmoins cela demanderait d'avantage d'heures de travail que celles à disposition. Nous laissons donc cette possibilité comme une éventuelle amélioration future.\\
				
		Le \textit{template engine} étant choisi, il nous reste encore à définir quelles variables seront nécessaires pour la génération des tables du côté de la personne voulant écrire un \textit{template} pour un langage cible:
		\begin{itemize}
			\item Table LALR
			\subitem (subdivisée par type d'actions ?)
			\item Nombre/liste des états
			\item Nombre/liste des terminaux
			\item Nombre/liste des non-terminaux
			\item Nombre d'états à réduire pour chaque non-terminal
			\item Nom de la règle associée pour chaque état\\
		\end{itemize}
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\textwidth]{../diagrams/misc/template}
			\caption{Processus de compilation d'un \textit{template} avec un contexte}
		\end{figure}
		
		Ces variables seront placées dans un module \hs{PP.Templates.Lr}, les comportements communs seront quant à eux placés dans \hs{PP.Template}:
		\begin{minted}{haskell}
			-- dans `PP.Template`:
			class Template context where
				-- |Put the context into StringTemplate attributes
				attributes :: context -> StringTemplate String -> StringTemplate String
				-- |Compile a template with a given context
				compile :: context -> String -> String
				compile c t = render $ attributes c $ newSTMP t
				
			-- dans `PP.Templates.Lr`:
			newtype LrContext = LrContext Int -- exemple
			
			-- |Construct the context for LR table
			context :: Int -> LrContext
			context = LrContext
			
			instance Template LrContext where
				attributes (LrContext x) = setAttribute "x" x
		\end{minted}
		\captionof{listing}{Approche pour la partie \textit{template}}
		
		\paragraph{}
		Cette approche est extensible et sépare les différentes responsabilités. Le code \hs{compile (context 3) "it's the number $x$"} donnera en sortie: \texttt{"it's the number 3"}.\\
		
		Le contexte ici pour la table LR est plus complexe. Le tableau suivant résume les différentes variables disponibles ainsi que leurs champs:
		\begin{table}[H]
			\centering
			\begin{tabular}{llll}
				\textbf{Type} & \textbf{Champ} & \textbf{Type du champ} & \textbf{Commentaires}\\
				\hline
				\hs{LrContext} & \hs{states} & \hs{[LrContextState]} & \textit{States informations}\\
				 & \hs{terms} & \hs{[LrContextTerm]} & \textit{Terminals informations}\\
				 & \hs{nonTerms} & \hs{[LrContextNonTerm]} & \textit{Non-terminals informations (without length)}\\
				 & \hs{table} & \hs{LrContextTable} & \textit{LR table informations}\\
				\hs{LrContextState} & \hs{id} & \hs{Int} & \textit{State ID}\\
				 & \hs{alt} & \hs{LrContextNonTerm} & \textit{Associated non-terminal (not impl. yet)}\\
				\hs{LrContextTerm} & \hs{symbol} & \hs{Char} & \textit{Terminal symbol}\\
				 & \hs{isEmpty} & \hs{Bool} & \textit{It's the EMPTY symbol?}\\
				\hs{LrContextNonTerm} & \hs{name} & \hs{String} & \textit{Non-terminal name}\\
				 & \hs{length} & \hs{Int} & \textit{Rule length (right side)}\\
				\hs{LrContextTable} & \hs{rows} & \hs{[LrContextTableRow]} & \textit{Table flatten in rows only}\\
				 & \hs{total} & \hs{Int} & \textit{Total rows (with errors)}\\
				\hs{LrContextTableRow} & \hs{state} & \hs{LrContextState} & \textit{Row state}\\
				 & \hs{isTerm} & \hs{Bool} & \textit{Row state is associated with ?}\\
				 & \hs{term} & \hs{LrContextTerm} & \textit{Row is associated with terminal}\\
				 & \hs{nonTerm} & \hs{LrContextNonTerm} & \textit{Row is associated with non-terminal}\\
				 & \hs{action} & \hs{LrContextAction} & \textit{Associated action}\\
				\hs{LrContextAction} & \hs{isReduce} & \hs{Bool} & \textit{Is action reduce?}\\
				 & \hs{isShift} & \hs{Bool} & \textit{Is action shift?}\\
				 & \hs{isGoto} & \hs{Bool} & \textit{Is action goto?}\\
				 & \hs{isError} & \hs{Bool} & \textit{Is action error?}\\
				 & \hs{isAccept} & \hs{Bool} & \textit{Is action accept?}\\
				 & \hs{shift} & \hs{Int} & \textit{Shift value}\\
				 & \hs{goto} & \hs{Int} & \textit{Goto value}\\
				 & \hs{reduce} & \hs{LrContextNonTerm} & \textit{Reduce associated non-terminal (with length)}\\
			\end{tabular}
			\caption{Variables interpolables pour le \textit{template} LR}
		\end{table}
		
		Ces champs nous offre toutes les informations dont nous avions besoin pour l'écriture d'un \textit{template}. Nous avons ci-dessous le premier modèle, qui génère simplement la table LR:
		\inputminted{text}{../../doc/templates/lr-table}
		\captionof{listing}{Template générant la table LR simplement}
		
		\paragraph{}
		Ce \textit{template} nous donne en sortie (exemple avec une grammaire simple):
		\begin{minted}{text}
			STATE 12
			TERM 6
			EMPTY
			(
			x
			)
			+
			*
			NONTERM 3
			E
			F
			T
			TABLE 108
			ROW 41
			0 NONTERM E GOTO 5
			0 NONTERM F GOTO 4
			0 NONTERM T GOTO 1
			0 TERM ( SHIFT 2
			0 TERM x SHIFT 3
			1 TERM ) REDUCE E 1
			1 TERM + SHIFT 6
			1 TERM EMPTY REDUCE E 1
			2 NONTERM E GOTO 7
			2 NONTERM F GOTO 4
			2 NONTERM T GOTO 1
			2 TERM ( SHIFT 2
			2 TERM x SHIFT 3
			3 TERM ) REDUCE F 1
			3 TERM * REDUCE F 1
			3 TERM + REDUCE F 1
			3 TERM EMPTY REDUCE F 1
			4 TERM ) REDUCE T 1
			4 TERM * SHIFT 8
			4 TERM + REDUCE T 1
			4 TERM EMPTY REDUCE T 1
			5 TERM EMPTY ACCEPT
			6 NONTERM E GOTO 9
			6 NONTERM F GOTO 4
			6 NONTERM T GOTO 1
			6 TERM ( SHIFT 2
			6 TERM x SHIFT 3
			7 TERM ) SHIFT 10
			8 NONTERM F GOTO 4
			8 NONTERM T GOTO 11
			8 TERM ( SHIFT 2
			8 TERM x SHIFT 3
			9 TERM ) REDUCE E 3
			9 TERM EMPTY REDUCE E 3
			10 TERM ) REDUCE F 3
			10 TERM * REDUCE F 3
			10 TERM + REDUCE F 3
			10 TERM EMPTY REDUCE F 3
			11 TERM ) REDUCE T 3
			11 TERM + REDUCE T 3
			11 TERM EMPTY REDUCE T 3
		\end{minted}
		
		Cette sortie peut être utilisée par un autre programme pour nourrir une table LR dans n'importe quel langage.
		
		\subsection{Intégration au CLI}
			L'intégration au CLI consiste à simplement ajouter une option \texttt{--template FILENAME} à la sous-commande \texttt{lalr}. Le CLI compile ensuite le fichier modèle avec la table générée:
			\begin{minted}{console}
				$ pp -s lalr -f grammar.ebnf --template template.foo > output.foo
			\end{minted}
			
	\section{Démonstration en C\#}
	\label{sec:demonstration-en-csharp}
		PP est désormais capable de lire une grammaire EBNF, de générer la table LALR correspondante, et de compiler un fichier \textit{template}. Dans cette section nous allons utiliser tout cela, pour démontrer le fonctionnement global ainsi que l'accomplissement des objectifs principaux du cahier des charges.\\
		
		La démonstration se sépare en plusieurs parties:
		\begin{itemize}
			\item Définition de la grammaire ISO CNC (déjà fait)
			\item Écriture d'un programme en ISO CNC (déjà fait)
			\item Validation de la grammaire (déjà fait)
			\item Écriture d'un \textit{engine} en C\#
			\subitem + Avec construction de l'AST 
			\subitem + Avec attache de \textit{callback} sur l'AST
			\item Écriture du \textit{template} pour l'\textit{engine}
			\item Démonstration globale et finale
		\end{itemize}
		
		\subsection{Écriture de l'\textit{engine} C\#}
			Le moteur en C\# consiste principalement en un \textit{parser} LR, qui donne en sortie l'AST parsé. Nous avons donc repris le fonctionnement du \textit{parser} LR en Haskell pour le transposer en C\#. L'implémentation se trouve dans le dossier \texttt{trials/csharp-engine/}, en résumé:
			\begin{table}[H]
				\centering
				\begin{tabular}{ll}
					\texttt{Program.cs} & \textit{Main}\\
					\texttt{engine/LrAction.cs} & Définition des actions\\
					\texttt{engine/LrAst.cs} & Définition d'un AST dynamique\\
					\texttt{engine/LrConfig.cs} & Configuration du \textit{parser} LR\\
					\texttt{engine/LrEvaluate.cs} & Attache de \textit{callback}\\
					\texttt{engine/LrParser.cs} & \textit{Parser} LR\\
					\texttt{engine/LrTable.cs} & Interface pour la table LR\\
				\end{tabular}
				\caption{Structure de l'\textit{engine} C\#}
			\end{table}
			
			Le point important à noter est \texttt{LrTable}. Grâce à cette approche, l'écriture du \textit{template} n'aura qu'à dériver cette interface pour fonctionner avec l'\textit{engine}. Nous verrons cela dans la partie suivante.
		
		\subsection{Écriture du \textit{template} pour l'\textit{engine}}
			Comme mentionné à la fin de la partie précédente, le \textit{template} doit dériver l'interface \texttt{LrTable} pour être utilisable par le moteur:
			\inputminted{csharp}{../../doc/templates/csharp-table.cs}
			\captionof{listing}{\textit{template} pour l'\textit{engine} C\# (fichier \texttt{doc/templates/csharp-table.cs})}
			
			\paragraph{}
			Le langage de \texttt{HStringTemplate} étant un peu lourd à lire, voici un exemple de compilation:
			\begin{minted}{csharp}
				public LrTableImpl()
				{
					// ...
					actions = new Dictionary<Tuple<int, char>, LrAction>()
					{
						{ Tuple.Create(0, '('), new LrAction(LrAction.Type.Shift, 2) },
						{ Tuple.Create(0, 'x'), new LrAction(LrAction.Type.Shift, 3) },
						{ Tuple.Create(1, ')'), new LrAction(LrAction.Type.Reduce, 1, "E") },
						// ...
					};
					gotos = new Dictionary<Tuple<int, string>, LrAction>()
					{
						{ Tuple.Create(0, "E"), new LrAction(LrAction.Type.Goto, 4) },
						{ Tuple.Create(0, "F"), new LrAction(LrAction.Type.Goto, 5) },
						// ...
					};
				}
			\end{minted}
			
		\subsection{Validation du \textit{pipeline}}
			Avant de faire la démonstration en ISO CNC, qui possède un code assez conséquent, nous allons valider la solution avec un exemple plus simple.\\
			
			Partons donc d'une grammaire simple:
			\inputminted{ebnf}{../../doc/grammars/test.ebnf}
			\captionof{listing}{Grammaire EBNF simple}
			
			\paragraph{}
			Compilons-la avec notre \textit{template}:
			\begin{minted}{text}
				$ pp -s lalr -f simple.ebnf --template csharp.cs > LrTableImpl.cs
				$
			\end{minted}
			\captionof{listing}{Compilation d'une table LALR avec un \textit{template}}
			
			\paragraph{} 
			Maintenant que nous avons notre fichier \texttt{LrTableImpl.cs}, et que nous avons corrigé son contenu (les \texttt{/* INSERT ... */}), nous pouvons écrire un interpréteur simple (notons la ligne 14 qui utilise \texttt{LrTableImpl.cs}):
			\inputminted{csharp}{../../trials/csharp-engine/csharp-engine/Program.cs}
			\captionof{listing}{Utilisation de l'\textit{engine} C\#}
			
			\paragraph{}
			À l'exécution, on obtient:
			\begin{minted}{text}
				success, AST:
				-
				|- statement
				||- expression
				|||- term
				||||- factor
				|||||- digit
				||||||- 2
				|||-  
				|||- expression
				||||- term
				|||||- factor
				||||||- digit
				|||||||- 3
				|||||- *
				|||||- term
				||||||- factor
				|||||||- (
				|||||||- expression
				||||||||- term
				|||||||||- factor
				||||||||||- digit
				|||||||||||- 1
				||||||||-  
				||||||||- expression
				|||||||||- term
				||||||||||- factor
				|||||||||||- digit
				||||||||||||- 3
				|||||||- )
				
				result:
				-
				|- 14
				
				press a key to quit...
			\end{minted}
			\captionof{listing}{Sortie de l'\textit{engine} C\# pour un exemple simple}
			
			\paragraph{}
			Le \textit{pipeline} fonctionne !\\
			
			Il apparaît après cette démonstration qu'il n'est pas nécessaire de faire la même avec le langage ISO CNC, comme initialement prévu. En effet cela n'apporterait aucune valeur ajoutée.\\
			
			Nous pouvons résumer la démonstration ainsi:
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.7\textwidth]{../diagrams/misc/exemple-pipeline}
				\caption{\textit{Pipeline} de la démonstration}
			\end{figure}
			
	\section{Planification de la phase III}		
		Comme on a pu le voir dans la section précédente, \textit{platinum parsing} réponds désormais à tous les objectifs que nous nous avions fixé pour la phase II (phase minimale). Nous pouvons à présent penser aux prochaines étapes, plusieurs choix sont possibles:
		\begin{itemize}
			\item Ajout de l'analyse lexicale (\textit{lexer})
			\subitem En plus de l'analyseur syntaxique déjà présent (\textit{parser})
			\item Intégration à un éditeur de texte
			\subitem Soit un IDE dédié, soit un plugin pour un éditeur existant
			\item Peaufinages en général
			\subitem Corrections des \textit{issues}, ajout de nouvelles fonctionnalités, etc.
			\item Mise en ligne
			\subitem \textit{Landing page}, documentation \textit{github}, etc.\\
		\end{itemize}
		
		Si tous ces choix sont pertinents, il est cependant difficile de savoir si tous seront réalisables dans le temps imparti à la phase III. Nous devons donc choisir l'ordre dans lequel nous voulons attaquer ces différentes étapes.\\
		
		La principale question est entre le \textit{lexer} ou l'intégration à un éditeur. Concrètement nous allons privilégier le \textit{lexer} si les gains (performances, fonctionnalités) associés sont conséquents. Pour savoir cela nous allons donc commencer par une étape d'analyse qui consistera à quantifier ces gains, et ainsi nous pourrons choisir quelle étape réaliser en premier.\\
		
		Voici donc la planification pour les 6 dernières semaines:
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|l}
				\textbf{Ordre} & \textbf{Durée} & \textbf{Tâche}\\
				\hline
				1 & 1 semaine & Analyse des gains du \textit{lexer}\\
				2 ou 3 & 2 semaines & Ajout du \textit{lexer}\\
				2 ou 3 & 1 semaine & Intégration à un éditeur\\
				4 & 1 semaine & Mise en ligne, peaufinages\\
				& 1 semaine & Semaine tampon\\
			\end{tabular}
			\caption{Planification de la phase III}
		\end{table}
		
		Nous affectons une semaine tampon dans le cas où l'une des tâches prendrait plus de temps que prévu.
		
	\section{Analyse des gains de l'analyse lexicale}
		Ici nous allons analyser les apports possibles avec l'ajout d'un \textit{lexer} (analyseur lexical). Plusieurs aspects sont à prendre en compte:
		\begin{itemize}
			\item Quels sont les gains en terme de performances ?
			\item Quels sont les gains sur la chaîne de compilation ?
			\item Quels sont les gains en terme de fonctionnalités ?
			\item Quels sont les gains conceptuellement parlant ?\\
		\end{itemize}
		
		Nous allons prendre ces différentes questions dans l'ordre.
		
		\subsection{Quels sont les gains en terme de performances ?}
			Pour mesurer les performances, nous allons comparer les temps d'exécution de deux \textit{engine}: l'un sans \textit{lexer} et l'autre avec. Les grammaires sont simples:
			\begin{minted}{ebnf}
				(* Grammaire sans lexer *)
				expr = number, { binop, number } ;
				binop = "+" | "-" ;
				number = digit without zero, { digit } ;
				digit = "0" | digit without zero ;
				digit without zero = "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" ;
				
				(* Grammaire avec lexer *)
				expr = number, { binop, number } ;
				binop = (* tokenized *) ;
				number = (* tokenized *) ;
			\end{minted}
			\captionof{listing}{Grammaires de test pour l'analyse des gains du \textit{lexer}}
			
			\paragraph{}
			Ces grammaires lisent des nombres avec des plus et des moins entre deux, par exemple: \texttt{7382+83-8389-89+34}.\\
			
			Chaque \textit{engine} devra faire les étapes suivantes:
			\begin{enumerate}
				\item Lecture de l'entrée
				\item Analyse syntaxique
				\subitem + Analyse lexicale pour le deuxième \textit{engine}
				\item Évaluation de l'AST obtenu\\
			\end{enumerate}
			
			Ces étapes ont été mesurées avec une entrée de taille variable, avec $N$ le nombre de nombres, et $max$ la borne supérieure des nombres générés aléatoirement. Par exemple avec $N=3$ et $max=100$: \texttt{23-4+99}.\\
			
			\begin{table}[H]
				\centering
				\begin{tabular}{l|l|l|l|l}
					\textbf{$N$} & \textbf{$max$} & \textbf{\textit{Sans} [ms]} & \textbf{\textit{Avec} [ms]} & \textbf{Gain}\\
					\hline
					10000 & 100 & 441 & 230 & 1.92\\
					1000 & 1000 & 21 & 5 & 4.20\\
					100 & 10000 & 4 & 0 & -\\
					10 & 100000 & 0 & 0 & -\\
					10000 & 10000 & 933 & 256 & 3.64\\
					10000 & 1000000 & 4911 & 297 & 16.54\\
					10000 & 100000000 & 10294 & 251 & 41.01\\
				\end{tabular}
				\caption{Comparaison entre \textit{avec} et \textit{sans} \textit{lexer}}
			\end{table}
			
			On constate aisément que quelque soit les paramètres d'entrées, la version avec \textit{lexer} est toujours meilleure que celle sans \textit{lexer}.\\

			Le code source pour ce test est dans le dossier \texttt{./trials/csharp-lexer-analysis/}. Notons encore que le \textit{lexer} implémenté est très simple, ce qui implique que les résultats ci-dessus ne sont pas représentatifs à 100\%. 
		
		\subsection{Quels sont les gains sur la chaîne de compilation ?}
			Comme on a pu le voir, l'ajout du \textit{lexer} apporte un gain conséquent en terme de performances. Cela s'explique assez facilement, en effet la conséquence directe de cet ajout est que la table LALR est plus simple. Ce qui implique donc un AST plus simple/petit, donc plus rapidement construit et évalué. Tout cela vient du fait que l'entrée est une suite de \textit{token} et non pas de caractères.\\
			
			L'ajout de l'analyse lexicale en début de compilation apporte donc un grand plus sur toute la suite de la chaîne.
		
		\subsection{Quels sont les gains en terme de fonctionnalités ?}
			Ici aussi l'analyse est assez simple. L'ajout du \textit{lexer} permet à l'utilisateur d'écrire des grammaires plus simples. En effet, certaines règles deviennent inutiles, et peuvent être réécrite à l'aide d'expressions régulières:
			\begin{minted}{ebnf}
				(* Grammaire sans lexer *)
				number = digit without zero, { digit } ;
				digit = "0" | digit without zero ;
				digit without zero = "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" ;
				
				(* Grammaire avec lexer *)
				number = (* exemple: /[1-9][0-9]*/ *) ; 
			\end{minted}
			\captionof{listing}{Simplification d'une grammaire avec les expressions régulières}
		
		\subsection{Quels sont les gains conceptuellement parlant ?}
			Le principal gain conceptuel est très important: la \textit{séparation des responsabilités}. Celui-ci apporte en plus la \textit{factorisation} du code ainsi qu'une meilleure \textit{extensibilité} de la chaîne de compilation.
		
		\subsection{Conclusion de l'analyse}			
			On s'aperçoit tout de suite que l'analyse lexicale apporte beaucoup, et ce sur de multiple aspects. Nous concluons donc qu'il est plus pertinent d'effectuer cet ajout à PP en premier, puis nous pourrons attaquer la partie "intégration à un éditeur de texte".\\
			
			Pour clore cette section et appuyer notre décision, voici un extrait du \textit{Dragon Book} \cite{dragonbook}, page 103, partie 3.1.1:
			\begin{quote}
				La partie analyse du compilateur est en principe décomposée en une phase d'analyse lexicale et une phase d'analyse syntaxique pour de multiples raisons.
				\begin{enumerate}
					\item La simplicité de développement est l'aspect le plus important. La séparation entre analyse lexicale et analyse syntaxique permet souvent de simplifier au moins l'une de ces tâches. Par exemple, un analyseur syntaxique qui aurait à traiter blancs et commentaires comme des unités syntaxiques serait considérablement plus complexe qu'un autre qui considérerait que blancs et commentaires ont déjà été éliminés par un analyseur lexical.
					\item Le compilateur est plus efficace. Un analyseur lexical séparé permet d'appliquer des techniques spécifiques qui ne servent qu'à l'analyse lexicale et non au travail de l'analyseur syntaxique. De plus, des techniques spécifiques de mise en mémoire tampon pour la lecture des caractères d'entrée peuvent accélérer significativement le compilateur.
					\item La portabilité du compilateur est améliorée. En effet, les spécificités liées aux interfaces d'entrée peuvent être circonscrites à l'analyseur lexical.
				\end{enumerate}
			\end{quote} 
			
	\section{Intégration de l'analyse lexicale}
		Nous avons vu dans la section précédente que l'analyse lexicale (\textit{lexer}) est un plus pour PP. Nous allons donc à présent nous pencher sur son intégration dans le produit actuel. Pour obtenir une meilleure vision du travail à effectuer, nous avons commencé par lire le chapitre 3 du Dragon Book \cite{dragonbook} qui concerne l'analyse lexicale. À partir de cela les sous-tâches suivantes ont pu être posées:
		\begin{enumerate}
			\item Intégration des motifs lexicaux au fichier de grammaire
			\subitem + Définir la syntaxe utilisée dans la grammaire
			\subitem + Définir l'AST pour les motifs lexicaux
			
			\item Effectuer la séparation \textit{lexer} / \textit{parser}
			\subitem Remplacer les terminaux par des motifs
			\subitem Modifier l'AST de l'EBNF en conséquence
			
			\item Génération des automates du \textit{lexer}
			\subitem + De l'AST vers un AFN 
			\subitem + De l'AFN vers un AFD
			\subitem + Éventuellement d'autres approches/optimisations sont possibles
			
			\item Implémentation du \textit{lexer} complet
			\subitem + Définir la représentation des \textit{tokens}
			
			\item Intégration et tests
			\subitem + Intégration au \textit{parser} déjà existant
			\subitem + Intégration au compilateur de \textit{template}
			\subitem + Tester l'ensemble sur une grammaire complexe\\
		\end{enumerate} 
		
		Nous allons attaquer ces différentes étapes dans l'ordre.
		
		\subsection{Définition des expressions régulières et ajout à la grammaire}
			\todo{}
			
		\subsection{Séparation des parties \textit{lexer} et des parties \textit{parser}}
			\todo{}
			
		\subsection{Génération des automates pour l'analyse lexicale}
			\todo{}
			
		\subsection{Implémentation du \textit{lexer} complet}
			\todo{}
			
		\subsection{Intégration à PP et tests}
			\todo{}
			
	\section{TODO}
		\todo{}
	
	\section{Annexes}
			
		\subsection{Liste des figures}
			\begingroup
				\renewcommand{\section}[2]{}
				\listoffigures
			\endgroup
			
		\subsection{Liste des tables}
			\begingroup
				\renewcommand{\section}[2]{}
				\listoftables
			\endgroup
			
		\subsection{Liste des codes}
			\begingroup
				\renewcommand{\section}[2]{}
				\listoflistings
			\endgroup
			
		\subsection{Critères testés pour le choix du langage}
		\label{subsec:criteres-testes-pour-le-choix-du-langage}
			Cette section contient les détails des différents critères pour chaque langage testé. Pour rappel ces critères sont:
			\begin{enumerate}
				\item Le langage a une communauté active et des ressources sur internet
				\item Le langage possède une ou des bibliothèques dans le domaine du \textit{parsing}
				\item L'implémentation d'un parser de test simple est aisée\\
			\end{enumerate}
			
			Concernant le 3ème critère, comme nous devrons implémenter la grammaire EBNF dans le cadre de ce TB, nous allons créer pour ce test un parser pour une grammaire EBNF simplifiée. Puis nous allons tester ce parser sur le fichier suivant:
			\begin{verbatim}
				grammar=identifier;
				identifier=letter,<letter>,digit;
				letter='a'|'b'|'c';
				digit='1'|'2'|'3';
				<test>='un test',<test>;
				<a2>=<a>,<b>|<b>;
			\end{verbatim}
			
			Pour simplification, nous avons uniquement:
			\begin{itemize}
				\item La définition de règle avec \texttt{=} : \texttt{<rule>=<expr>;}
				\item La concaténation avec \texttt{,} : \texttt{<a>,<b>}
				\item Le choix avec \texttt{|} : \texttt{<a>|<b>}
				\item Les terminaux entourés par des guillemets simples: \texttt{'a'}
				\item Les non-terminaux entourés par \texttt{<>} ou pas
				\item Pas de gestion des espaces, tabulations, ...
				\item Pas de gestion de la priorité des opérateurs, ni des parenthèses\\
			\end{itemize}
			
			Le parser doit pouvoir sortir l'AST correspondant.
					
			\subsubsection{Langage Haskell}
				Concernant Haskell, le lien suivant contient tous les pointeurs utiles en ressources: \url{https://www.haskell.org/documentation}. Pour ce qui est de la communauté, les questions et réponses sont quotidiennes sur \textit{stack overflow} ainsi que sur \textit{reddit}. Il y a également un wiki communautaire.\\
				
				Le lien suivant liste différentes bibliothèques présente pour ce langage: \url{https://wiki.haskell.org/Applications_and_libraries}. Plusieurs outils ou bibliothèques pour le parsing existent et sont listés ici: \url{https://wiki.haskell.org/Applications_and_libraries/Compiler_tools}. De plus ce langage est la base de plusieurs compilateurs, voir: \url{https://wiki.haskell.org/Applications_and_libraries/Compilers_and_interpreters}\\
				
				L'implémentation du parser simplifié se trouve dans le dossier \texttt{./trials/haskell-simple-ebnf/}. La taille du module EBNF fait moins de 50 lignes, comprenant l'AST ainsi que le parser. Nous avons utilisé la bibliothèque Parsec \cite{parsec} qui utilise une syntaxe très proche de l'EBNF, ce qui est très pratique. Pour 1 million d'itérations, le parsing prend environ 140ms. Notons qu'il y a de nombreuses ressources concernant Parsec.
				
				\inputminted{haskell}{../../trials/haskell-simple-ebnf/src/EBNF.hs}
				\captionof{listing}{Utilisation de Parsec avec Haskell}
		
			\subsubsection{Langage C\#}
				C\# est un langage développé par Microsoft avec la base de .NET derrière. Les ressources sur Internet ne manquent pas et la communauté est bonne.\\
				
				La bibliothèque Irony \cite{irony} permet de construire un parser très simplement. En effet Irony utilise la surcharge des opérateurs pour avoir une syntaxe proche de celle de l'EBNF, ce qui est très pratique.\\
				
				L'implémentation du parser simplifié se trouve dans le dossier \texttt{./trials/csharp-simple-ebnf}. La taille du module EBNF fait moins de 50 lignes, et est très simple à comprendre. Notons tout de même que Irony possède assez peu de ressources sur Internet.
				
				\inputminted{csharp}{../../trials/csharp-simple-ebnf/csharp-simple-ebnf/EBNF.cs}
				\captionof{listing}{Utilisation de Irony avec C\#}
			
			\subsubsection{Langage F\#}
				F\# possède plusieurs tutoriaux sur Internet et bénéficie de .NET derrière: \url{http://fsharp.org/learn.html}. Cependant les questions sur \textit{stack overflow} ne sont pas courante, et celles-ci ne reçoivent pas forcément des réponses. \\
				
				La bibliothèque FParsec \cite{fparsec} a une API équivalente à Parsec de Haskell. Il y a plusieurs tutoriaux et la documentation est claire.\\
				
				L'implémentation se trouve dans le dossier \texttt{./trials/fsharp-simple-ebnf}. Celle-ci est naturellement proche de celle en Haskell, cependant F\# oblige de définir une fonction avant qu'elle ne soit utilisée, et construire des règles récursives est plus compliqué. La taille du module EBNF fait également moins de 50 lignes.
				
				\inputminted{fsharp}{../../trials/fsharp-simple-ebnf/fsharp-simple-ebnf/EBNF.fs}
				\captionof{listing}{Utilisation de FParsec avec F\#}
	
		\subsection{Références}
			\begingroup
				\renewcommand{\section}[2]{}
				\begin{thebibliography}{9}
					
					\bibitem{dragonbook} Compilateurs : Principes, techniques et outils,\\
						2ème édition - Pearson Education,\\
						A. Aho, M. Lam, R. Sethi et J. Ullman\\
					
					\bibitem{bnf} BNF, Backus-Naur form,\\
						\url{https://en.wikipedia.org/wiki/Backus\%E2\%80\%93Naur_form}\\
						
					\bibitem{ebnf} EBNF, Extended Backus-Naur form, used to express a context-free grammar,\\ 
						\url{https://en.wikipedia.org/wiki/Extended\_Backus\%E2\%80\%93Naur_form},\\
						\url{https://www.iso.org/standard/26153.html},\\
						\url{http://standards.iso.org/ittf/PubliclyAvailableStandards/s026153_ISO_IEC_14977_1996(E).zip}\\
					
					\bibitem{goldparser} GOLD Parsing System, GOLD is a free parsing system that you can use to develop your own programming languages, scripting languages and interpreters,\\
						\url{http://www.goldparser.org/}\\
						
					\bibitem{lalr} LALR, Look-Ahead LR parser,\\
						\url{https://en.wikipedia.org/wiki/LALR_parser}\\
						
					\bibitem{irony} Irony, .NET Language Implementation Kit,\\
						\url{https://irony.codeplex.com/}\\
						
					\bibitem{ast} AST, Abstract Syntax Tree,\\
						\url{https://en.wikipedia.org/wiki/Abstract_syntax_tree}\\
						
					\bibitem{git} Git, free and open source distributed version control system,\\
						\url{https://git-scm.com/}\\
					
					\bibitem{github} Github, web-based Git or version control repository,\\
						\url{https://github.com/}\\
											
					\bibitem{latex} LaTeX, a document preparation system,\\
						\url{http://www.latex-project.org/}\\
					
					\bibitem{haskell} Haskell, a standardized, general-purpose purely functional programming language,\\
						\url{https://www.haskell.org/}\\
					
					\bibitem{stack} Stack, a cross-platform program for developing Haskell projects,\\
						\url{https://docs.haskellstack.org/en/stable/README/}\\
					
					\bibitem{cabal} Cabal, a system for building and packaging Haskell libraries and programs,\\
						\url{https://www.haskell.org/cabal/}\\	
					
					\bibitem{atom} Atom, a text editor that's modern, approachable, yet hackable to the core,\\
						\url{https://atom.io/}\\
					
					\bibitem{parsec} Parsec, an industrial-strength parser library for Haskell,\\
						\url{https://hackage.haskell.org/package/parsec}\\
						
					\bibitem{fparsec} FParsec, a parser combinator library for F\#,\\
						\url{http://www.quanttec.com/fparsec/}\\
						
					\bibitem{haddock} Haddock, A Haskell Documentation Tool,\\
						\url{https://www.haskell.org/haddock/}\\
						
					\bibitem{hspec} Hspec, A testing framework for Haskell,\\
						\url{http://hackage.haskell.org/package/hspec}\\
						
					\bibitem{optparse} optparse-applicative, parsing options on the command line,\\
						\url{https://hackage.haskell.org/package/optparse-applicative}\\
						
					\bibitem{ebnftobnf} EBNF to BNF,\\
						\url{http://lampwww.epfl.ch/teaching/archive/compilation-ssc/2000/part4/parsing/node3.html}\\
						
					\bibitem{heterocephalus} Heterocephalus, A type-safe template engine for working with popular front end development tools,\\
						\url{https://hackage.haskell.org/package/heterocephalus}\\
						
					\bibitem{hstringtemplate} HStringTemplate, A port of the Java library by Terrence Parr,\\
						\url{http://hackage.haskell.org/package/HStringTemplate}\\
						
					\bibitem{lr} LR Parser,\\
						\url{https://en.wikipedia.org/wiki/LR_parser}\\
						
				\end{thebibliography}
			\endgroup
	
\end{document}\grid
